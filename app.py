import streamlit as st
import importlib.util
import sys
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from persiantools.jdatetime import JalaliDate
import os
import io
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
import numpy as np
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.lib import colors
from reportlab.lib import colors
import io
import streamlit as st
from reportlab.lib.pagesizes import A4
from reportlab.lib import colors
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
from reportlab.lib.styles import getSampleStyleSheet
import io
from reportlab.platypus import Image  # Ø§Ø¶Ø§ÙÙ‡ Ø¨Ø±Ø§ÛŒ ØªØµÙˆÛŒØ±
from sklearn.ensemble import IsolationForest
from reportlab.lib.styles import ParagraphStyle
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
from pulp import LpProblem, LpMinimize, LpVariable, LpStatus, value
import statsmodels.api as sm
from prophet import Prophet
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.holtwinters import ExponentialSmoothing
from pulp import *
# Ø¨Ø±Ø±Ø³ÛŒ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§
required_libraries = [
    "streamlit", "pandas", "plotly", "matplotlib", "seaborn",
    "sklearn", "persiantools", "reportlab", "xlsxwriter", "pulp", "statsmodels", "prophet"
]

def check_libraries():
    missing = []
    for lib in required_libraries:
        if importlib.util.find_spec(lib) is None:
            missing.append(lib)
    if missing:
        st.error(f"âš ï¸ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ± Ù†ØµØ¨ Ù†ÛŒØ³ØªÙ†Ø¯: {', '.join(missing)}\nÙ„Ø·ÙØ§Ù‹ Ø¢Ù†â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø§ Ø¯Ø³ØªÙˆØ± Ø²ÛŒØ± Ù†ØµØ¨ Ú©Ù†ÛŒØ¯:\n`pip install {' '.join(missing)}`")
        st.stop()

check_libraries()

st.set_page_config(page_title="Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ù¾Ø§ÛŒØ´ Ø¨Ø±Ù‚ Ú©Ù†Ø³Ø§Ù†ØªØ±Ù‡", layout="wide")

# ----------- Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ùˆ ÙÙˆÙ†Øª -----------
page_bg_img = '''
<style>
.stApp {
    background-image: url("https://images.unsplash.com/photo-1581093588401-1ebdd1b6b47d?ixlib=rb-4.0.3&auto=format&fit=crop&w=1470&q=80");
    background-size: cover;
    background-attachment: fixed;
    background-color: rgba(0, 0, 0, 0.5);
    color: white;
    font-family: Tahoma, Vazir, sans-serif;
    font-size: 16px;
}
</style>
'''
st.markdown(page_bg_img, unsafe_allow_html=True)

# ----------- Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù„ÙˆÚ¯Ùˆ -----------
st.sidebar.subheader("ğŸ·ï¸ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù„ÙˆÚ¯Ùˆ Ø´Ø±Ú©Øª")
uploaded_logo = st.sidebar.file_uploader("Ø¢Ù¾Ù„ÙˆØ¯ Ù„ÙˆÚ¯Ùˆ (PNG/JPG)", type=["png", "jpg", "jpeg"])
if uploaded_logo:
    try:
        st.sidebar.image(uploaded_logo, width=150)
    except Exception as e:
        st.sidebar.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù„ÙˆÚ¯Ùˆ: {e}")

# ----------- Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§Ú©Ø³Ù„ -----------
def load_excel(file):
    log_messages = []  # Ù„ÛŒØ³Øª Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§

    try:
        xls = pd.ExcelFile(file)
        log_messages.append(f"ğŸ“Œ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø¨Ø§ {len(xls.sheet_names)} Ø´ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯: {xls.sheet_names}")
    except Exception as e:
        log_messages.append(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„: {e}")
        return pd.DataFrame(), log_messages

    dfs = []
    for sheet in xls.sheet_names:
        df_sheet = pd.read_excel(file, sheet_name=sheet, header=None)
        df_sheet = df_sheet.dropna(axis=1, how="all")
        log_messages.append(f"ğŸ“Š Ø´ÛŒØª {sheet} Ø¨Ø§ {df_sheet.shape[0]} Ø±Ø¯ÛŒÙ Ùˆ {df_sheet.shape[1]} Ø³ØªÙˆÙ† Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.")

        header_row = None
        for i, row in df_sheet.iterrows():
            row_str = row.astype(str)
            if row_str.str.contains(r'^\d{4}/\d{2}/\d{2}$', na=False).any() or pd.to_datetime(row_str, errors="coerce").notna().any():
                header_row = i - 1
                break
        if header_row is None:
            log_messages.append(f"âš ï¸ Ø´ÛŒØª {sheet} ÙØ§Ù‚Ø¯ Ù‡Ø¯Ø± Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª Ùˆ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯.")
            continue

        raw_headers = df_sheet.iloc[header_row].fillna("Ø¨Ø¯ÙˆÙ† Ø¹Ù†ÙˆØ§Ù†")
        seen, unique_headers = {}, []
        for col in raw_headers:
            if col not in seen:
                seen[col] = 0
                unique_headers.append(col)
            else:
                seen[col] += 1
                unique_headers.append(f"{col}_{seen[col]}")

        df_data = df_sheet[header_row + 1:].copy()
        df_data.columns = unique_headers
        df_data = df_data.rename(columns={df_data.columns[0]: "ØªØ§Ø±ÛŒØ®"})
        log_messages.append(f"ğŸ“‹ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø´ÛŒØª {sheet}: {list(df_data.columns)}")

        # Ø¨Ø±Ø±Ø³ÛŒ Ùˆ ØªØ¨Ø¯ÛŒÙ„ ØªØ§Ø±ÛŒØ®
        df_data["ØªØ§Ø±ÛŒØ®"] = df_data["ØªØ§Ø±ÛŒØ®"].astype(str)
        if df_data["ØªØ§Ø±ÛŒØ®"].str.contains(r'^\d{4}/\d{2}/\d{2}$', na=False).any():
            def parse_jalali_date(date_str):
                try:
                    year, month, day = map(int, date_str.split('/'))
                    return JalaliDate(year, month, day).to_gregorian()
                except:
                    return pd.NaT
            df_data["ØªØ§Ø±ÛŒØ®"] = df_data["ØªØ§Ø±ÛŒØ®"].apply(parse_jalali_date)
            log_messages.append(f"ğŸ“… ØªØ§Ø±ÛŒØ®â€ŒÙ‡Ø§ÛŒ Ø´ÛŒØª {sheet} Ø¨Ù‡â€ŒØ¹Ù†ÙˆØ§Ù† ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù†Ø¯.")
        else:
            df_data["ØªØ§Ø±ÛŒØ®"] = pd.to_datetime(df_data["ØªØ§Ø±ÛŒØ®"], errors="coerce")

        df_data = df_data.dropna(subset=["ØªØ§Ø±ÛŒØ®"])
        if df_data.empty:
            log_messages.append(f"âš ï¸ Ø´ÛŒØª {sheet} Ù¾Ø³ Ø§Ø² Ø­Ø°Ù ØªØ§Ø±ÛŒØ®â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø®Ø§Ù„ÛŒ Ø§Ø³Øª.")
            continue

        df_data["ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ"] = df_data["ØªØ§Ø±ÛŒØ®"].map(lambda x: JalaliDate(x).strftime('%Y/%m/%d') if pd.notnull(x) else "")
        for col in df_data.columns:
            if col not in ["ØªØ§Ø±ÛŒØ®", "ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ"]:
                df_data[col] = pd.to_numeric(df_data[col], errors="coerce")
        df_data["Ú©Ø§Ø±Ø®Ø§Ù†Ù‡"] = sheet
        dfs.append(df_data)

    if not dfs:
        log_messages.append("âš ï¸ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø§Ø² Ø´ÛŒØªâ€ŒÙ‡Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯.")
        return pd.DataFrame(), log_messages

    df = pd.concat(dfs, ignore_index=True)
    log_messages.append(f"ğŸ“Š DataFrame Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø§ {df.shape[0]} Ø±Ø¯ÛŒÙ Ùˆ {df.shape[1]} Ø³ØªÙˆÙ† Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯.")
    return df, log_messages

# ----------- Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø¨Ø§ Ú©Ø´ -----------
@st.cache_data
def get_data(file):
    with st.spinner("â³ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§..."):
        return load_excel(file)

# ----------- Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ Excel -----------
default_excel_path = "Ù†Ù…ÙˆÙ†Ù‡_Ú©Ù†Ø³Ø§Ù†ØªØ±Ù‡.xlsx"
uploaded_file = st.file_uploader("ğŸ“‚ Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ú©Ù†Ø³Ø§Ù†ØªØ±Ù‡ Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯", type=["xlsx"])
if uploaded_file is None:
    if os.path.exists(default_excel_path):
        uploaded_file = default_excel_path
        st.info("ğŸ“Œ Ø§Ø² ÙØ§ÛŒÙ„ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª: Ù†Ù…ÙˆÙ†Ù‡_Ú©Ù†Ø³Ø§Ù†ØªØ±Ù‡.xlsx")
    else:
        st.warning("âš ï¸ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯Ù‡ Ùˆ ÙØ§ÛŒÙ„ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ù‡Ù… Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.")
        st.stop()

df, logs = get_data(uploaded_file)

# Ù†Ù…Ø§ÛŒØ´ Ù„Ø§Ú¯â€ŒÙ‡Ø§ ÙÙ‚Ø· Ø¯Ø± Expander
with st.expander("ğŸ” Ú¯Ø²Ø§Ø±Ø´ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„"):
    for msg in logs:
        st.info(msg)

# Ø§Ú¯Ø± Ø¯Ø§Ø¯Ù‡ Ø®Ø§Ù„ÛŒ Ø¨ÙˆØ¯ Ù…ØªÙˆÙ‚Ù Ú©Ù†
if df.empty:
    st.error("âš ï¸ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø§Ø² ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.")
    st.stop()

# ----------- ÙÛŒÙ„ØªØ± Ú©Ø§Ø±Ø®Ø§Ù†Ù‡ Ùˆ ØªØ§Ø±ÛŒØ® -----------
factories = df["Ú©Ø§Ø±Ø®Ø§Ù†Ù‡"].unique().tolist()
st.sidebar.header("ğŸ­ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ø§Ø±Ø®Ø§Ù†Ù‡")
select_all = st.sidebar.button("Ø§Ù†ØªØ®Ø§Ø¨ Ù‡Ù…Ù‡")
if select_all:
    selected_factories = factories
else:
    selected_factories = st.sidebar.multiselect("Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ø§Ø±Ø®Ø§Ù†Ù‡ (Ú©Ø§Ø±Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§)", factories, default=factories)
if not selected_factories:
    st.warning("âš ï¸ Ù„Ø·ÙØ§Ù‹ Ø­Ø¯Ø§Ù‚Ù„ ÛŒÚ© Ú©Ø§Ø±Ø®Ø§Ù†Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.")
    st.stop()
filtered_df = df[df["Ú©Ø§Ø±Ø®Ø§Ù†Ù‡"].isin(selected_factories)]

st.sidebar.header("ğŸ¯ ÙÛŒÙ„ØªØ± Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ")
min_date, max_date = filtered_df["ØªØ§Ø±ÛŒØ®"].min(), filtered_df["ØªØ§Ø±ÛŒØ®"].max()
start_date, end_date = st.sidebar.date_input("Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ", [min_date, max_date])

# Ù†Ù…Ø§ÛŒØ´ ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ Ø¯Ø± Ø²ÛŒØ± ØªÙ‚ÙˆÛŒÙ…
st.sidebar.markdown(f"**ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ Ø´Ø±ÙˆØ¹:** {JalaliDate(start_date).strftime('%Y/%m/%d')}")
st.sidebar.markdown(f"**ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ Ù¾Ø§ÛŒØ§Ù†:** {JalaliDate(end_date).strftime('%Y/%m/%d')}")

# ... (Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ: ÙÛŒÙ„ØªØ± Ú©Ø§Ø±Ø®Ø§Ù†Ù‡ Ùˆ ØªØ§Ø±ÛŒØ®)

mask = (filtered_df["ØªØ§Ø±ÛŒØ®"] >= pd.to_datetime(start_date)) & (filtered_df["ØªØ§Ø±ÛŒØ®"] <= pd.to_datetime(end_date))
filtered_df = filtered_df.loc[mask]
if filtered_df.empty:
    st.warning("âš ï¸ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ø§Ù†ØªØ®Ø§Ø¨â€ŒØ´Ø¯Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
    st.stop()

# ğŸ‘ˆ ØªØ§Ø¨Ø¹ monte_carlo_simulation Ø±Ùˆ Ø§ÛŒÙ†Ø¬Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù† (Ù‚Ø¨Ù„ Ø§Ø² ØªØ¨â€ŒÙ‡Ø§)
@st.cache_data
def monte_carlo_simulation(base_consumption, scenarios, n_sim=1000, change_factor=20):
    """
    Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ Ø¨Ø§ ÙØ§Ú©ØªÙˆØ± ØªØºÛŒÛŒØ± Ù…ØªØºÛŒØ±.
    """
    results = []
    low_bound = 1 - change_factor / 100
    high_bound = 1 + change_factor / 100
    for _ in range(n_sim):
        sim = base_consumption * np.random.uniform(low_bound, high_bound, len(scenarios))
        results.append(sim)
    return pd.DataFrame(results, columns=scenarios)

# Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ ØªØ±Ø¬Ù…Ù‡ Ø¨Ø±Ø§ÛŒ fallback Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ (Ú¯Ø³ØªØ±Ø´â€ŒÛŒØ§ÙØªÙ‡) - Ø¨Ù‡ ØµÙˆØ±Øª Ø¬Ù‡Ø§Ù†ÛŒ ØªØ¹Ø±ÛŒÙ Ø´Ø¯
translations = {
    "Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØµØ±Ù ØªØ¬Ù‡ÛŒØ²Ø§Øª": "Average Equipment Consumption",
    "ØªØ¬Ù‡ÛŒØ²": "Equipment",
    "Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØµØ±Ù": "Avg Consumption",
    "Ø±ÙˆÙ†Ø¯ Ù…ØµØ±Ù": "Consumption Trend",
    "Ù…Ø§Ù‡ Ø´Ù…Ø³ÛŒ": "Jalali Month",
    "Ù…Ø¬Ù…ÙˆØ¹": "Total",
    "Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†": "Average",
    "Ù…Ø§Ù‡": "Month",
    "Ø±ÙˆØ²": "Day",
    "Ù…ØµØ±Ù": "Consumption",
    "ØªØ§Ø±ÛŒØ®": "Date",
    "Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ": "Forecast",
    "KPI": "KPI",
    "Ù…Ø¬Ù…ÙˆØ¹ Ù…ØµØ±Ù": "Total Consumption",
    "Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØµØ±Ù": "Average Consumption",
    "Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ù…ØµØ±Ù": "Max Consumption",
    "Ø¯Ø±ØµØ¯ ØªØºÛŒÛŒØ±": "Percent Change",
    "MAE": "MAE",
    "RMSE": "RMSE",
    "Ù…Ø¯Ù„": "Model",
    "RÂ²": "RÂ²",
    "p-value": "p-value",
    "UCL": "UCL",
    "LCL": "LCL",
    "Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒâ€ŒÙ‡Ø§": "Anomalies",
    "CO2": "CO2",
    "Ø§Ù†ØªØ´Ø§Ø± CO2": "CO2 Emissions",
    "Ù‡Ø²ÛŒÙ†Ù‡": "Cost",
    "Ù…ØµØ±Ù Ø§ÙˆØ¬": "Peak Consumption",
    "Ù…ØµØ±Ù Ø®Ø§Ø±Ø¬ Ø§ÙˆØ¬": "Off-Peak Consumption",
    "Ú©Ù„": "Total",
    "Ù†Ù…ÙˆØ¯Ø§Ø± Ù…ØµØ±Ù Ù…Ø§Ù‡ÛŒØ§Ù†Ù‡": "Monthly Consumption Chart",
    "Heatmap Ù…ØµØ±Ù ØªØ¬Ù‡ÛŒØ²Ø§Øª": "Equipment Consumption Heatmap",
    "Ú¯Ø²Ø§Ø±Ø´ ØªØ¬Ù‡ÛŒØ²Ø§Øª": "Equipment Report",
    "Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…ØµØ±Ù ØªØ¬Ù‡ÛŒØ²Ø§Øª": "Equipment Consumption Forecast",
    "KPI Ù¾ÛŒØ´Ø±ÙØªÙ‡": "Advanced KPI",
    "ØªØ­Ù„ÛŒÙ„ Ø±ÙˆÙ†Ø¯ ØªØºÛŒÛŒØ±Ø§Øª": "Trend Change Analysis",
    "Ø¬Ø¯ÙˆÙ„ Ø®Ø·Ø§Ù‡Ø§": "Error Table",
    "ØªØ­Ù„ÛŒÙ„ Ø¯ÛŒØªØ§": "Data Analysis",
    "ØªØ´Ø®ÛŒØµ Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒâ€ŒÙ‡Ø§": "Anomaly Detection",
    "Ú¯Ø²Ø§Ø±Ø´ Ø²ÛŒØ³Øªâ€ŒÙ…Ø­ÛŒØ·ÛŒ": "Environmental Report",
    "Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ù‡Ø§ÛŒ ØµÙ†Ø¹ØªÛŒ": "Comparison with Industry Standards",
    "ØªØ­Ù„ÛŒÙ„ Ù‡Ø²ÛŒÙ†Ù‡ Ùˆ Ø¨ÙˆØ¯Ø¬Ù‡": "Cost and Budget Analysis",
    "Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ ØªØ¹Ø§Ù…Ù„ÛŒ Ø²Ù†Ø¯Ù‡": "Live Interactive Dashboard",
    "Ú¯Ø²Ø§Ø±Ø´ Ø³ÙØ§Ø±Ø´ÛŒ": "Custom Report",
    "Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§": "Scenario Simulation",
    "Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ LP": "LP Optimization",
    "Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ NLP": "NLP Optimization",
    # ğŸ‘ˆ Ø§Ú¯Ø± Ø¹Ù†Ø§ÙˆÛŒÙ† Ø¯ÛŒÚ¯Ù‡â€ŒØ§ÛŒ Ø¯Ø§Ø±ÛŒØŒ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†
}

# ----------- Tab Ù‡Ø§ -----------
tab1, tab2, tab3, tab4, tab5, tab6, tab7,tab8,tab9,tab10,tab11,tab12,tab13,tab14,tab15,tab16,tab17,tab18 = st.tabs([
    "KPI & Ù…Ù‚Ø§ÛŒØ³Ù‡", "Ø±ÙˆÙ†Ø¯ Ù…ØµØ±Ù", "Ù…Ø§Ù‡Ø§Ù†Ù‡", "Heatmap", 
    "Ø¬Ø¯ÙˆÙ„ & Ø®Ø±ÙˆØ¬ÛŒ", "Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ", "KPI Ù¾ÛŒØ´Ø±ÙØªÙ‡","ğŸ“Š ØªØ­Ù„ÛŒÙ„ Ø±ÙˆÙ†Ø¯ ØªØºÛŒÛŒØ±Ø§Øª","Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…ØµØ±Ù ØªØ¬Ù‡ÛŒØ²Ø§Øª Ø¨Ø§ Machine Learning","ØªØ­Ù„ÛŒÙ„ Ø¯ÛŒØªØ§","ğŸš¨ ØªØ´Ø®ÛŒØµ Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒâ€ŒÙ‡Ø§ Ùˆ Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§","ğŸŒ Ú¯Ø²Ø§Ø±Ø´ Ø²ÛŒØ³Øªâ€ŒÙ…Ø­ÛŒØ·ÛŒ Ùˆ Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ","ğŸ­ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ù‡Ø§ÛŒ ØµÙ†Ø¹ØªÛŒ","ğŸ’° ØªØ­Ù„ÛŒÙ„ Ù‡Ø²ÛŒÙ†Ù‡ Ùˆ Ø¨ÙˆØ¯Ø¬Ù‡","ğŸ“± Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ ØªØ¹Ø§Ù…Ù„ÛŒ Ø²Ù†Ø¯Ù‡","ğŸ“§ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ÛŒ Ø³ÙØ§Ø±Ø´ÛŒ Ùˆ Ø§ÛŒÙ…ÛŒÙ„","ğŸ² Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§","âš™ï¸ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ (LP/NLP)",
])

# ... (Ø¨Ù‚ÛŒÙ‡ Ú©Ø¯ Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±)

# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ (ØªØ¬Ù‡ÛŒØ²Ø§Øª)
columns = filtered_df.select_dtypes(include="number").columns.tolist()
columns = [c for c in columns if c not in ["Ú©Ø§Ø±Ø®Ø§Ù†Ù‡", "ØªØ§Ø±ÛŒØ®", "ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ"]]

if not columns:
    st.warning("âš ï¸ Ø³ØªÙˆÙ† Ø¹Ø¯Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ Ùˆ Ø¨Ø±Ø®ÛŒ Ø¨Ø®Ø´â€ŒÙ‡Ø§ ØºÛŒØ±ÙØ¹Ø§Ù„ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.")

# ÙÙˆÙ†Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ø±Ø§ÛŒ PDF: B Nazanin
fonts = {
    "Vazir": r"C:\path\to\Vazir.ttf",  # ğŸ‘ˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ùˆ Ù…Ø³ÛŒØ± Ø±Ùˆ ØªÙ†Ø¸ÛŒÙ… Ú©Ù† (Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† B Nazanin)
    "BNazanin": r"D:\BNazanin.ttf"     # Ù†Ú¯Ù‡ Ø¯Ø§Ø± Ø¨Ù‡â€ŒØ¹Ù†ÙˆØ§Ù† fallback
}
available_fonts = [name for name, path in fonts.items() if os.path.exists(path)]
font_name = "Vazir" if "Vazir" in available_fonts else ("BNazanin" if "BNazanin" in available_fonts else "Helvetica")

# ØªØ§Ø¨Ø¹ generate_pdf Ø³Ø§Ø¯Ù‡â€ŒØ´Ø¯Ù‡ (Ø¨Ø¯ÙˆÙ† Ù¾Ø±Ø¯Ø§Ø²Ø´ elements):
def generate_pdf(title, elements, buffer, pagesize=A4):
    doc = SimpleDocTemplate(buffer, pagesize=pagesize)
    styles = getSampleStyleSheet()
    
    # Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ ØªØ±Ø¬Ù…Ù‡ Ø¨Ø±Ø§ÛŒ fallback Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ (Ú¯Ø³ØªØ±Ø´â€ŒÛŒØ§ÙØªÙ‡) - Ø­Ø§Ù„Ø§ Ø¬Ù‡Ø§Ù†ÛŒ Ø§Ø³ØªØŒ Ø§Ù…Ø§ Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ‡ Ø´Ø¯
    global translations
    
    use_persian = available_fonts and font_name != "Helvetica"
    if use_persian:
        try:
            pdfmetrics.registerFont(TTFont(font_name, fonts[font_name]))
            title_style = ParagraphStyle('Title', fontName=font_name, fontSize=18, alignment=1,  # ğŸ‘ˆ alignment=1 Ø¨Ø±Ø§ÛŒ RIGHT (RTL)
                                         spaceAfter=30, spaceBefore=20)
            normal_style = ParagraphStyle('Normal', fontName=font_name, fontSize=12, alignment=1)  # RTL
            
            # RTL reshape Ø¹Ù†ÙˆØ§Ù†
            try:
                import arabic_reshaper
                from bidi.algorithm import get_display
                title = get_display(arabic_reshaper.reshape(title))
            except ImportError:
                st.warning("Ø¨Ø±Ø§ÛŒ RTL Ø¨Ù‡ØªØ±ØŒ arabic-reshaper Ùˆ python-bidi Ø±Ùˆ Ù†ØµØ¨ Ú©Ù†.")
                pass  # Ø¨Ø¯ÙˆÙ† reshape
        except Exception as e:
            st.warning(f"ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ Ø®Ø·Ø§ Ø¯Ø§Ø¯ ({e}). Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø³ÙˆØ¦ÛŒÚ†.")
            use_persian = False
            title = translations.get(title, title)  # ØªØ±Ø¬Ù…Ù‡ Ø¹Ù†ÙˆØ§Ù†
    else:
        title_style = styles['Title']
        title = translations.get(title, title)  # ØªØ±Ø¬Ù…Ù‡ Ø¹Ù†ÙˆØ§Ù†
    
    elements.insert(0, Paragraph(title, title_style))
    doc.build(elements)
    buffer.seek(0)

with tab1:
    st.subheader("ğŸ“Œ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØµØ±Ù Ú†Ù†Ø¯ ØªØ¬Ù‡ÛŒØ²")
    
    selected_columns = st.multiselect("ğŸ”Œ Ø§Ù†ØªØ®Ø§Ø¨ ØªØ¬Ù‡ÛŒØ²Ø§Øª:", columns)
    
    if selected_columns:
        mean_values = filtered_df[selected_columns].mean().reset_index()
        mean_values.columns = ["ØªØ¬Ù‡ÛŒØ²", "Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØµØ±Ù"]
        mean_values["Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØµØ±Ù"] = mean_values["Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØµØ±Ù"].round(2)  # ğŸ‘ˆ ÙØ±Ù…Øª Ø§Ø¹Ø¯Ø§Ø¯
        
        chart_height = max(400, len(selected_columns) * 50)
        
        y_max = mean_values["Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØµØ±Ù"].max()
        y_range = [0, y_max * 1.1]
        
        fig_bar = go.Figure(data=[
            go.Bar(
                x=mean_values["ØªØ¬Ù‡ÛŒØ²"],
                y=mean_values["Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØµØ±Ù"],
                text=mean_values["Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØµØ±Ù"].round(2),
                textposition="outside",
                textfont=dict(family="Tahoma, Arial, sans-serif", size=14, color="black"),
                marker_color='blue'
            )
        ])
        
        fig_bar.update_layout(
            title_text="Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØµØ±Ù ØªØ¬Ù‡ÛŒØ²Ø§Øª",
            title_font=dict(family="Tahoma, Arial, sans-serif", size=20, color="black"),
            xaxis=dict(
                title_text="ØªØ¬Ù‡ÛŒØ²",
                tickangle=-45 if len(selected_columns) > 3 else 0,
                title_font=dict(family="Tahoma, Arial, sans-serif", size=16, color="black"),
                tickfont=dict(family="Tahoma, Arial, sans-serif", size=14, color="black")
            ),
            yaxis=dict(
                title_text="Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØµØ±Ù",
                title_font=dict(family="Tahoma, Arial, sans-serif", size=16, color="black"),
                tickfont=dict(family="Tahoma, Arial, sans-serif", size=14, color="black"),
                range=y_range
            ),
            uniformtext_minsize=8,
            uniformtext_mode='hide',
            plot_bgcolor='white',  # ğŸ‘ˆ Ø³ÙÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø­Ø§Ø´ÛŒÙ‡ Ù…Ø´Ú©ÛŒ Ø¯Ø± PNG
            paper_bgcolor='white',
            height=chart_height
        )
        
        st.plotly_chart(fig_bar, use_container_width=True)
        
        st.dataframe(
            mean_values.style
                .format({"Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØµØ±Ù": "{:.2f}"})
                .background_gradient(cmap="Blues", subset=["Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØµØ±Ù"])
        )

        # Ø®Ø±ÙˆØ¬ÛŒ PDF Ø¨Ø±Ø§ÛŒ Tab1 (Ø¨Ù‡Ø¨ÙˆØ¯ÛŒØ§ÙØªÙ‡: ØªØ±Ø¬Ù…Ù‡ Ùˆ reshape Ù‚Ø¨Ù„ Ø§Ø² Table)
        if st.button("â¬‡ï¸ Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF Tab1"):
            buffer = io.BytesIO()
            elements = []
            
            data = [mean_values.columns.tolist()] + mean_values.values.tolist()
            
            # ØªØ±Ø¬Ù…Ù‡ Ù‡Ø¯Ø±Ù‡Ø§ Ø§Ú¯Ø± Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
            translations_local = {
                "ØªØ¬Ù‡ÛŒØ²": "Equipment",
                "Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØµØ±Ù": "Avg Consumption",
            }
            use_persian = available_fonts and font_name != "Helvetica"
            if not use_persian and data and isinstance(data[0], list) and len(data[0]) >= 2:
                data[0][0] = translations_local.get(data[0][0], data[0][0])
                data[0][1] = translations_local.get(data[0][1], data[0][1])
            
            # Reshape Ù…ØªÙ†â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ RTL Ø§Ú¯Ø± ÙØ§Ø±Ø³ÛŒ (ÙÙ‚Ø· Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§)
            if use_persian:
                try:
                    import arabic_reshaper
                    from bidi.algorithm import get_display
                    for row in data:
                        for i, cell in enumerate(row):
                            if isinstance(cell, str):
                                row[i] = get_display(arabic_reshaper.reshape(cell))
                except ImportError:
                    st.warning("Ø¨Ø±Ø§ÛŒ RTL Ø¯Ø± Ø¬Ø¯ÙˆÙ„ØŒ arabic-reshaper Ùˆ python-bidi Ø±Ùˆ Ù†ØµØ¨ Ú©Ù†.")
            
            table = Table(data)
            table.setStyle(TableStyle([
                ('BACKGROUND', (0,0), (-1,0), colors.lightgrey),  # Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ø¹Ù†ÙˆØ§Ù†
                ('TEXTCOLOR', (0,0), (-1,0), colors.black),       # Ù…ØªÙ† Ø¹Ù†ÙˆØ§Ù†
                ('GRID', (0,0), (-1,-1), 0.5, colors.lightgrey),  # ğŸ‘ˆ grid Ú©Ù…â€ŒØ±Ù†Ú¯ (Ù†Ù‡ Ù…Ø´Ú©ÛŒ)
                ('ALIGN', (0,0), (-1,-1), 'CENTER')
            ]))
            elements.append(table)
            
            # ØªÙˆÙ„ÛŒØ¯ ØªØµÙˆÛŒØ± Ø¨Ø§ Ú©ÛŒÙÛŒØª Ø¨Ù‡ØªØ± (Ù†ÛŒØ§Ø² Ø¨Ù‡ kaleido: pip install kaleido)
            img_buf = io.BytesIO()
            fig_bar.write_image(img_buf, format='png', width=800, height=chart_height, scale=2)
            img_buf.seek(0)
            elements.append(Image(img_buf, width=500, height=chart_height // 2))
            
            title = "Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØµØ±Ù ØªØ¬Ù‡ÛŒØ²Ø§Øª"
            if not use_persian:
                title = translations.get(title, title)
            generate_pdf(title, elements, buffer)
            
            # ğŸ‘ˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø§ getvalue() Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†
            pdf_data = buffer.getvalue()
            st.download_button(
                label="Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF",
                data=pdf_data,
                file_name="tab1.pdf",
                mime="application/pdf"
            )
            
            # Ú†Ú© ÙÙˆÙ†Øª
            if not available_fonts:
                st.warning("âš ï¸ ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. PDF Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯.")

# ----------- Tab2: Ø±ÙˆÙ†Ø¯ Ù…ØµØ±Ù -----------
with tab2:
    st.subheader("ğŸ“ˆ Ø±ÙˆÙ†Ø¯ Ù…ØµØ±Ù ØªØ¬Ù‡ÛŒØ²Ø§Øª")
    selected_multi = st.multiselect("ğŸ§  Ø§Ù†ØªØ®Ø§Ø¨ ØªØ¬Ù‡ÛŒØ²(Ù‡Ø§):", columns, default=[columns[0]] if columns else [])
    
    time_granularity = st.radio("â±ï¸ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ù†Ù…Ø§ÛŒØ´:", ["Ø±ÙˆØ²Ø§Ù†Ù‡", "Ù…Ø§Ù‡Ø§Ù†Ù‡", "Ø³Ø§Ù„ÛŒØ§Ù†Ù‡"])
    
    if selected_multi:
        df_plot = filtered_df.copy()
        
        if time_granularity == "Ø±ÙˆØ²Ø§Ù†Ù‡":
            df_plot["ØªØ§Ø±ÛŒØ® Ù†Ù…Ø§ÛŒØ´"] = df_plot["ØªØ§Ø±ÛŒØ®"].map(lambda x: JalaliDate(x).strftime('%Y/%m/%d'))
        elif time_granularity == "Ù…Ø§Ù‡Ø§Ù†Ù‡":
            df_plot["ØªØ§Ø±ÛŒØ® Ù†Ù…Ø§ÛŒØ´"] = df_plot["ØªØ§Ø±ÛŒØ®"].map(lambda x: JalaliDate(x).strftime('%Y/%m'))
            df_plot = df_plot.groupby("ØªØ§Ø±ÛŒØ® Ù†Ù…Ø§ÛŒØ´")[selected_multi].sum().reset_index()
        elif time_granularity == "Ø³Ø§Ù„ÛŒØ§Ù†Ù‡":
            df_plot["ØªØ§Ø±ÛŒØ® Ù†Ù…Ø§ÛŒØ´"] = df_plot["ØªØ§Ø±ÛŒØ®"].map(lambda x: JalaliDate(x).strftime('%Y'))
            df_plot = df_plot.groupby("ØªØ§Ø±ÛŒØ® Ù†Ù…Ø§ÛŒØ´")[selected_multi].sum().reset_index()
        
        fig_line = px.line(
            df_plot,
            x="ØªØ§Ø±ÛŒØ® Ù†Ù…Ø§ÛŒØ´",
            y=selected_multi,
            title="ğŸ“ˆ Ø±ÙˆÙ†Ø¯ Ù…ØµØ±Ù Ø¨Ø±Ù‚",
            template="plotly_white",
            markers=True
        )
        fig_line.update_layout(xaxis_title="ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ", yaxis_title="Ù…ØµØ±Ù (MWh)")
        st.plotly_chart(fig_line, use_container_width=True)

        # Ø®Ø±ÙˆØ¬ÛŒ PDF Ø¨Ø±Ø§ÛŒ Tab2
        if st.button("â¬‡ï¸ Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF Tab2"):
            buffer = io.BytesIO()
            elements = []
            
            # ØªÙˆÙ„ÛŒØ¯ ØªØµÙˆÛŒØ± Ø¨Ø§ Ú©ÛŒÙÛŒØª Ø¨Ù‡ØªØ± (Ù†ÛŒØ§Ø² Ø¨Ù‡ kaleido: pip install kaleido)
            img_buf = io.BytesIO()
            fig_line.write_image(img_buf, format='png', width=800, height=400, scale=2)
            img_buf.seek(0)
            elements.append(Image(img_buf, width=500, height=300))
            
            title = "Ø±ÙˆÙ†Ø¯ Ù…ØµØ±Ù ØªØ¬Ù‡ÛŒØ²Ø§Øª"
            if not use_persian:
                title = translations.get(title, title)
            generate_pdf(title, elements, buffer)
            
            # ğŸ‘ˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø§ getvalue() Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†
            pdf_data = buffer.getvalue()
            st.download_button(
                label="Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF",
                data=pdf_data,
                file_name="tab2.pdf",
                mime="application/pdf"
            )
            
            # Ú†Ú© ÙÙˆÙ†Øª
            if not available_fonts:
                st.warning("âš ï¸ ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. PDF Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯.")

# ----------- Tab3: Ù…Ø§Ù‡Ø§Ù†Ù‡ -----------
with tab3:
    st.subheader("ğŸ“† Ù†Ù…ÙˆØ¯Ø§Ø± Ù…ØµØ±Ù Ù…Ø§Ù‡ÛŒØ§Ù†Ù‡")
    
    filtered_df["Ù…Ø§Ù‡ Ø´Ù…Ø³ÛŒ"] = filtered_df["ØªØ§Ø±ÛŒØ®"].map(lambda x: JalaliDate(x).strftime('%Y/%m'))
    
    if columns:
        monthly_column = st.selectbox("ğŸ“Œ Ø§Ù†ØªØ®Ø§Ø¨ ØªØ¬Ù‡ÛŒØ²:", columns)
        
        # Ú¯Ø±ÙˆÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ùˆ Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ
        monthly_df = filtered_df.groupby("Ù…Ø§Ù‡ Ø´Ù…Ø³ÛŒ")[monthly_column].sum().reset_index()
        monthly_df = monthly_df.sort_values("Ù…Ø§Ù‡ Ø´Ù…Ø³ÛŒ").reset_index(drop=True)  # Ø±ÛŒØ³Øª Ø§ÛŒÙ†Ø¯Ú©Ø³
        
        y_values = monthly_df[monthly_column].tolist()
        x_values = monthly_df["Ù…Ø§Ù‡ Ø´Ù…Ø³ÛŒ"].tolist()
        
        # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ùˆ Ú©Ù…ØªØ±ÛŒÙ† (Ø¨Ø§ Ø§ÛŒÙ†Ø¯Ú©Ø³ Ø¯Ø±Ø³Øª)
        idx_max = monthly_df[monthly_column].idxmax()
        idx_min = monthly_df[monthly_column].idxmin()
        
        # ğŸ‘ˆ ØªØºÛŒÛŒØ±: colors Ø±Ùˆ Ø¨Ù‡ bar_colors ØªØºÛŒÛŒØ± Ø¯Ø§Ø¯Ù…
        bar_colors = []  # ğŸ‘ˆ Ù†Ø§Ù… Ø¬Ø¯ÛŒØ¯: bar_colors
        for i in range(len(y_values)):
            if i == idx_max:
                bar_colors.append("green")
            elif i == idx_min:
                bar_colors.append("red")
            else:
                bar_colors.append("blue")
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø±
        fig_month = go.Figure(
            data=[go.Bar(
                x=x_values,
                y=y_values,
                text=[f"{v:.2f}" for v in y_values],
                textposition="outside",
                marker_color=bar_colors  # ğŸ‘ˆ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² bar_colors
            )]
        )
        
        fig_month.update_layout(
            title=f"ğŸ“Š Ù…ØµØ±Ù Ù…Ø§Ù‡ÛŒØ§Ù†Ù‡ {monthly_column}",
            xaxis_title="Ù…Ø§Ù‡ Ø´Ù…Ø³ÛŒ",
            yaxis_title="Ù…Ù‚Ø¯Ø§Ø± Ù…ØµØ±Ù",
            template="plotly_white",
            xaxis_tickangle=-45
        )
        
        st.plotly_chart(fig_month, use_container_width=True)

        # Ø®Ø±ÙˆØ¬ÛŒ PDF Ø¨Ø±Ø§ÛŒ Tab3 (Ø¨Ù‡Ø¨ÙˆØ¯ÛŒØ§ÙØªÙ‡)
        if st.button("â¬‡ï¸ Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF Tab3"):
            buffer = io.BytesIO()
            elements = []
            
            data = [monthly_df.columns.tolist()] + monthly_df.values.tolist()
            
            # ØªØ±Ø¬Ù…Ù‡ Ù‡Ø¯Ø±Ù‡Ø§ Ø§Ú¯Ø± Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
            translations_local = {
                "Ù…Ø§Ù‡ Ø´Ù…Ø³ÛŒ": "Jalali Month",
                monthly_column: "Consumption"
            }
            use_persian = available_fonts and font_name != "Helvetica"
            if not use_persian and data and isinstance(data[0], list) and len(data[0]) >= 2:
                data[0][0] = translations_local.get(data[0][0], data[0][0])
                data[0][1] = translations_local.get(data[0][1], data[0][1])
            
            # Reshape Ù…ØªÙ†â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ RTL Ø§Ú¯Ø± ÙØ§Ø±Ø³ÛŒ (ÙÙ‚Ø· Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§)
            if use_persian:
                try:
                    import arabic_reshaper
                    from bidi.algorithm import get_display
                    for row in data:
                        for i, cell in enumerate(row):
                            if isinstance(cell, str):
                                row[i] = get_display(arabic_reshaper.reshape(cell))
                except ImportError:
                    st.warning("Ø¨Ø±Ø§ÛŒ RTL Ø¯Ø± Ø¬Ø¯ÙˆÙ„ØŒ arabic-reshaper Ùˆ python-bidi Ø±Ùˆ Ù†ØµØ¨ Ú©Ù†.")
            
            table = Table(data)
            table.setStyle(TableStyle([
                ('BACKGROUND', (0,0), (-1,0), colors.lightgrey),  # Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ø¹Ù†ÙˆØ§Ù†
                ('TEXTCOLOR', (0,0), (-1,0), colors.black),       # Ù…ØªÙ† Ø¹Ù†ÙˆØ§Ù†
                ('GRID', (0,0), (-1,-1), 0.5, colors.lightgrey),  # ğŸ‘ˆ grid Ú©Ù…â€ŒØ±Ù†Ú¯ (Ù†Ù‡ Ù…Ø´Ú©ÛŒ)
                ('ALIGN', (0,0), (-1,-1), 'CENTER')
            ]))
            elements.append(table)
            
            # ØªÙˆÙ„ÛŒØ¯ ØªØµÙˆÛŒØ± Ø¨Ø§ Ú©ÛŒÙÛŒØª Ø¨Ù‡ØªØ± (Ù†ÛŒØ§Ø² Ø¨Ù‡ kaleido: pip install kaleido)
            img_buf = io.BytesIO()
            fig_month.write_image(img_buf, format='png', width=800, height=400, scale=2)
            img_buf.seek(0)
            elements.append(Image(img_buf, width=500, height=300))
            
            title = "Ù†Ù…ÙˆØ¯Ø§Ø± Ù…ØµØ±Ù Ù…Ø§Ù‡ÛŒØ§Ù†Ù‡"
            if not use_persian:
                title = translations.get(title, title)
            generate_pdf(title, elements, buffer)
            
            # ğŸ‘ˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø§ getvalue() Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†
            pdf_data = buffer.getvalue()
            st.download_button(
                label="Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF",
                data=pdf_data,
                file_name="tab3.pdf",
                mime="application/pdf"
            )
            
            # Ú†Ú© ÙÙˆÙ†Øª
            if not available_fonts:
                st.warning("âš ï¸ ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. PDF Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯.")

# ----------- Tab4: Heatmap -----------
# ----------- Tab4: Heatmap -----------
with tab4:
    st.subheader("ğŸ”¥ Heatmap Ù…ØµØ±Ù ØªØ¬Ù‡ÛŒØ²Ø§Øª Ø¨Ø§ Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø±Ù†Ú¯ Ù‚Ø§Ø¨Ù„ ØªÙ†Ø¸ÛŒÙ…")
    if columns:
        heat_col = st.selectbox("ğŸ“Œ Ø§Ù†ØªØ®Ø§Ø¨ ØªØ¬Ù‡ÛŒØ² Ø¨Ø±Ø§ÛŒ Heatmap:", columns)
        view_mode = st.radio("ğŸ”„ Ø­Ø§Ù„Øª Ù†Ù…Ø§ÛŒØ´:", ["Ø±ÙˆØ²Ø§Ù†Ù‡", "Ù…Ø§Ù‡Ø§Ù†Ù‡ Ù…Ø§ØªØ±ÛŒØ³ÛŒ"])

        df_hm = filtered_df.dropna(subset=[heat_col])
        
        if not df_hm.empty:
            df_hm["Ù…Ø§Ù‡"] = df_hm["ØªØ§Ø±ÛŒØ®"].dt.to_period("M")
            df_hm["Ø±ÙˆØ²"] = df_hm["ØªØ§Ø±ÛŒØ®"].dt.day

            default_min = df_hm[heat_col].min()
            default_max = df_hm[heat_col].max()
            st.sidebar.markdown("ğŸ¨ ØªÙ†Ø¸ÛŒÙ… Ø­Ø¯Ø§Ù‚Ù„ Ùˆ Ø­Ø¯Ø§Ú©Ø«Ø± Ø±Ù†Ú¯ Ù‡ÛŒØªâ€ŒÙ…Ù¾")
            user_min, user_max = st.sidebar.slider(
                "Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø±Ù†Ú¯ (Min Ùˆ Max):",
                float(default_min), float(default_max),
                (float(default_min), float(default_max))
            )

            colorscale = [
                [0.0, 'lightblue'],
                [0.5, 'yellow'],
                [1.0, 'red']
            ]

            # Ù…ØªØºÛŒØ± fig Ø±Ø§ Ø¯Ø± Ø§Ø¨ØªØ¯Ø§ÛŒ Ø´Ø±Ø· ØªØ¹Ø±ÛŒÙ Ú©Ù†ÛŒØ¯ ØªØ§ Ø®Ø·Ø§ÛŒ NameError Ø¯Ø± PDF Ù†Ú¯ÛŒØ±ÛŒØ¯
            fig = None

            if view_mode == "Ø±ÙˆØ²Ø§Ù†Ù‡":
                pivot_day = df_hm.pivot_table(index="Ø±ÙˆØ²", columns="Ù…Ø§Ù‡", values=heat_col, aggfunc="mean")
                if not pivot_day.empty:
                    pivot_display = pivot_day.copy()
                    pivot_display.index = pivot_display.index.astype(str)
                    pivot_display.columns = pivot_display.columns.astype(str)

                    fig = go.Figure(data=go.Heatmap(
                        z=pivot_display.values,
                        x=pivot_display.columns,
                        y=pivot_display.index,
                        colorscale=colorscale,
                        zmin=user_min,
                        zmax=user_max,
                        colorbar=dict(title=heat_col),
                        hovertemplate='Ø±ÙˆØ² %{y}<br>Ù…Ø§Ù‡ %{x}<br>Ù…ØµØ±Ù: %{z:.2f}<extra></extra>',
                        # ğŸ‘ˆ Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¨ÙˆØ±Ø¯Ø± Ùˆ ØªÙÚ©ÛŒÚ© Ø³Ù„ÙˆÙ„â€ŒÙ‡Ø§
                        xgap=1,  # ÙØ§ØµÙ„Ù‡ Ø§ÙÙ‚ÛŒ Ø¨ÛŒÙ† Ø³Ù„ÙˆÙ„â€ŒÙ‡Ø§ (Ø§ÛŒØ¬Ø§Ø¯ Ø®Ø· Ø³ÙÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø¨ÙˆØ±Ø¯Ø±)
                        ygap=1,  # ÙØ§ØµÙ„Ù‡ Ø¹Ù…ÙˆØ¯ÛŒ Ø¨ÛŒÙ† Ø³Ù„ÙˆÙ„â€ŒÙ‡Ø§
                        # Ø¨Ø±Ø§ÛŒ Ø¨ÙˆØ±Ø¯Ø± ØªÛŒØ±Ù‡â€ŒØªØ±ØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù† colorscale Ø±Ø§ Ø¨Ø§ Ø®Ø·ÙˆØ· Ø³ÙØ§Ø±Ø´ÛŒ ØªØ±Ú©ÛŒØ¨ Ú©Ø±Ø¯ØŒ Ø§Ù…Ø§ xgap/ygap Ø³Ø§Ø¯Ù‡â€ŒØªØ±ÛŒÙ† Ø±Ø§Ù‡ Ø§Ø³Øª
                    ))

                    fig.update_layout(
                        title=f"Heatmap Ø±ÙˆØ²Ø§Ù†Ù‡ - {heat_col}",
                        xaxis=dict(tickangle=-45, automargin=True),
                        yaxis=dict(autorange='reversed', automargin=True),
                        height=max(400, 20*len(pivot_display.index)),
                        width=max(700, 50*len(pivot_display.columns)),
                        # ğŸ‘ˆ Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¨ÙˆØ±Ø¯Ø± Ú©Ù„ÛŒ Ø¨Ù‡ Ù†Ù…ÙˆØ¯Ø§Ø±
                        plot_bgcolor='white',
                        paper_bgcolor='lightgray',  # Ø¨ÙˆØ±Ø¯Ø± Ø®Ø§Ø±Ø¬ÛŒ Ø®Ø§Ú©Ø³ØªØ±ÛŒ Ø±ÙˆØ´Ù†
                        margin=dict(l=50, r=50, t=50, b=50),  # Ø­Ø§Ø´ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ø¬Ø¯Ø§Ø³Ø§Ø²ÛŒ
                        # Ø¨Ø±Ø§ÛŒ Ø¨ÙˆØ±Ø¯Ø± Ø³Ù„ÙˆÙ„â€ŒÙ‡Ø§ØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø§Ø² annotations ÛŒØ§ shapes Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯ØŒ Ø§Ù…Ø§ xgap Ú©Ø§ÙÛŒ Ø§Ø³Øª
                    )
                    st.plotly_chart(fig, use_container_width=True)

            elif view_mode == "Ù…Ø§Ù‡Ø§Ù†Ù‡ Ù…Ø§ØªØ±ÛŒØ³ÛŒ":
                months = sorted(df_hm["Ù…Ø§Ù‡"].unique())
                matrix_data = pd.DataFrame()
                for m in months:
                    month_data = df_hm[df_hm["Ù…Ø§Ù‡"]==m].set_index("Ø±ÙˆØ²")[heat_col]
                    matrix_data[m] = month_data

                pivot_month = matrix_data.fillna(0)
                pivot_month_display = pivot_month.copy()
                pivot_month_display.index = pivot_month_display.index.astype(str)
                pivot_month_display.columns = pivot_month_display.columns.astype(str)

                fig = go.Figure(data=go.Heatmap(
                    z=pivot_month_display.values,
                    x=pivot_month_display.columns,
                    y=pivot_month_display.index,
                    colorscale=colorscale,
                    zmin=user_min,
                    zmax=user_max,
                    colorbar=dict(title=heat_col),
                    hovertemplate='Ø±ÙˆØ² %{y}<br>Ù…Ø§Ù‡ %{x}<br>Ù…ØµØ±Ù: %{z:.2f}<extra></extra>',
                    # ğŸ‘ˆ Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¨ÙˆØ±Ø¯Ø± Ùˆ ØªÙÚ©ÛŒÚ© Ø³Ù„ÙˆÙ„â€ŒÙ‡Ø§
                    xgap=1,  # ÙØ§ØµÙ„Ù‡ Ø§ÙÙ‚ÛŒ
                    ygap=1,  # ÙØ§ØµÙ„Ù‡ Ø¹Ù…ÙˆØ¯ÛŒ
                ))

                fig.update_layout(
                    title=f"Heatmap Ù…Ø§Ù‡Ø§Ù†Ù‡ Ù…Ø§ØªØ±ÛŒØ³ÛŒ - {heat_col}",
                    xaxis=dict(tickangle=-45, automargin=True),
                    yaxis=dict(autorange='reversed', automargin=True),
                    height=max(400, 20*len(pivot_month_display.index)),
                    width=max(700, 50*len(pivot_month_display.columns)),
                    # ğŸ‘ˆ Ø¨ÙˆØ±Ø¯Ø± Ú©Ù„ÛŒ
                    plot_bgcolor='white',
                    paper_bgcolor='lightgray',
                    margin=dict(l=50, r=50, t=50, b=50),
                )
                st.plotly_chart(fig, use_container_width=True)

            # ğŸ‘ˆ Ú†Ú© Ú©Ø±Ø¯Ù† fig Ù‚Ø¨Ù„ Ø§Ø² PDF
            if fig is not None:
                st.markdown("ğŸ“‹ **Ø¬Ø¯ÙˆÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ù„Ø§ØµÙ‡ Ø´Ø¯Ù‡**")
                monthly_summary = df_hm.groupby("Ù…Ø§Ù‡")[heat_col].agg(['sum','mean']).round(2)
                monthly_summary = monthly_summary.rename(columns={'sum':'Ù…Ø¬Ù…ÙˆØ¹', 'mean':'Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†'})
                st.dataframe(monthly_summary, use_container_width=True)

                # Ø®Ø±ÙˆØ¬ÛŒ PDF Ø¨Ø±Ø§ÛŒ Tab4
                if st.button("â¬‡ï¸ Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF Tab4"):
                    buffer = io.BytesIO()
                    elements = []
                    
                    # ØªÙˆÙ„ÛŒØ¯ ØªØµÙˆÛŒØ± Ø¨Ø§ Ú©ÛŒÙÛŒØª Ø¨Ù‡ØªØ± (Ù†ÛŒØ§Ø² Ø¨Ù‡ kaleido: pip install kaleido)
                    img_buf = io.BytesIO()
                    fig.write_image(img_buf, format='png', width=800, height=fig.layout.height, scale=2)
                    img_buf.seek(0)
                    elements.append(Image(img_buf, width=500, height=fig.layout.height // 2))
                    
                    data = [monthly_summary.columns.tolist()] + monthly_summary.values.tolist()
                    
                    # ØªØ±Ø¬Ù…Ù‡ Ù‡Ø¯Ø±Ù‡Ø§ Ø§Ú¯Ø± Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
                    translations_local = {
                        "Ù…Ø§Ù‡": "Month",
                        "Ù…Ø¬Ù…ÙˆØ¹": "Total",
                        "Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†": "Average"
                    }
                    use_persian = available_fonts and font_name != "Helvetica"
                    if not use_persian and data and isinstance(data[0], list) and len(data[0]) >= 2:
                        data[0][0] = translations_local.get(data[0][0], data[0][0])
                        data[0][1] = translations_local.get(data[0][1], data[0][1])
                        data[0][2] = translations_local.get(data[0][2], data[0][2])
                    
                    # Reshape Ù…ØªÙ†â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ RTL Ø§Ú¯Ø± ÙØ§Ø±Ø³ÛŒ (ÙÙ‚Ø· Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§)
                    if use_persian:
                        try:
                            import arabic_reshaper
                            from bidi.algorithm import get_display
                            for row in data:
                                for i, cell in enumerate(row):
                                    if isinstance(cell, str):
                                        row[i] = get_display(arabic_reshaper.reshape(cell))
                        except ImportError:
                            st.warning("Ø¨Ø±Ø§ÛŒ RTL Ø¯Ø± Ø¬Ø¯ÙˆÙ„ØŒ arabic-reshaper Ùˆ python-bidi Ø±Ùˆ Ù†ØµØ¨ Ú©Ù†.")
                    
                    table = Table(data)
                    table.setStyle(TableStyle([
                        ('BACKGROUND', (0,0), (-1,0), colors.lightgrey),  # Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ø¹Ù†ÙˆØ§Ù†
                        ('TEXTCOLOR', (0,0), (-1,0), colors.black),       # Ù…ØªÙ† Ø¹Ù†ÙˆØ§Ù†
                        ('GRID', (0,0), (-1,-1), 0.5, colors.lightgrey),  # ğŸ‘ˆ grid Ú©Ù…â€ŒØ±Ù†Ú¯ (Ù†Ù‡ Ù…Ø´Ú©ÛŒ)
                        ('ALIGN', (0,0), (-1,-1), 'CENTER')
                    ]))
                    elements.append(table)
                    
                    title = "Heatmap Ù…ØµØ±Ù ØªØ¬Ù‡ÛŒØ²Ø§Øª"
                    if not use_persian:
                        title = translations.get(title, title)
                    generate_pdf(title, elements, buffer)
                    
                    # ğŸ‘ˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø§ getvalue() Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†
                    pdf_data = buffer.getvalue()
                    st.download_button(
                        label="Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF",
                        data=pdf_data,
                        file_name="tab4.pdf",
                        mime="application/pdf"
                    )
                    
                    # Ú†Ú© ÙÙˆÙ†Øª
                    if not available_fonts:
                        st.warning("âš ï¸ ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. PDF Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯.")
            else:
                st.warning("âš ï¸ Ù†Ù…ÙˆØ¯Ø§Ø± Heatmap ØªÙˆÙ„ÛŒØ¯ Ù†Ø´Ø¯Ø› Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.")
        else:
            st.warning("âš ï¸ Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù‡ÛŒØªâ€ŒÙ…Ù¾ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")

# ----------- Tab5: Ø®Ø±ÙˆØ¬ÛŒ PDF (Ø¯Ø§Ø±Ù‡ØŒ ØªØºÛŒÛŒØ± ÙÙˆÙ†Øª) -----------
with tab5:
    st.subheader("ğŸ“ Ø®Ø±ÙˆØ¬ÛŒ PDF Ú¯Ø²Ø§Ø±Ø´ ØªØ¬Ù‡ÛŒØ²Ø§Øª")

    uploaded_file_tab5 = st.file_uploader("Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø¨Ø±Ø§ÛŒ Ø§ÛŒØ¬Ø§Ø¯ PDF", type=['xlsx'], key="tab5_uploader")
    if uploaded_file_tab5:
        df_tab5 = pd.read_excel(uploaded_file_tab5, sheet_name=0)

        buffer = io.BytesIO()
        elements = []

        styles = getSampleStyleSheet()
        use_persian = available_fonts and font_name != "Helvetica"
        if use_persian:
            try:
                pdfmetrics.registerFont(TTFont(font_name, fonts[font_name]))
                title_style = ParagraphStyle('Title', fontName=font_name, fontSize=18, alignment=1)
                normal_style = ParagraphStyle('Normal', fontName=font_name, fontSize=12, alignment=1)
            except Exception as e:
                st.warning(f"ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ Ø®Ø·Ø§ Ø¯Ø§Ø¯ ({e}). Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø³ÙˆØ¦ÛŒÚ†.")
                use_persian = False
        else:
            title_style = styles['Title']
            normal_style = styles['Normal']
        
        title = Paragraph("Ú¯Ø²Ø§Ø±Ø´ ØªØ¬Ù‡ÛŒØ²Ø§Øª", title_style)
        elements.append(title)
        elements.append(Spacer(1, 12))

        data = [df_tab5.columns.tolist()] + df_tab5.values.tolist()

        # ØªØ±Ø¬Ù…Ù‡ Ù‡Ø¯Ø±Ù‡Ø§ Ø§Ú¯Ø± Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
        translations_local = {
            "ØªØ¬Ù‡ÛŒØ²": "Equipment",
            # Add more as needed
        }
        if not use_persian and data and isinstance(data[0], list):
            for i, header in enumerate(data[0]):
                data[0][i] = translations_local.get(header, header)
        
        # Reshape Ù…ØªÙ†â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ RTL Ø§Ú¯Ø± ÙØ§Ø±Ø³ÛŒ (ÙÙ‚Ø· Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§)
        if use_persian:
            try:
                import arabic_reshaper
                from bidi.algorithm import get_display
                for row in data:
                    for i, cell in enumerate(row):
                        if isinstance(cell, str):
                            row[i] = get_display(arabic_reshaper.reshape(cell))
            except ImportError:
                st.warning("Ø¨Ø±Ø§ÛŒ RTL Ø¯Ø± Ø¬Ø¯ÙˆÙ„ØŒ arabic-reshaper Ùˆ python-bidi Ø±Ùˆ Ù†ØµØ¨ Ú©Ù†.")

        table = Table(data)
        table.setStyle(TableStyle([
            ('BACKGROUND', (0,0), (-1,0), colors.lightgrey),
            ('TEXTCOLOR', (0,0), (-1,0), colors.black),
            ('GRID', (0,0), (-1,-1), 1, colors.black),
            ('ALIGN', (0,0), (-1,-1), 'CENTER')
        ]))
        elements.append(table)

        title_str = "Ú¯Ø²Ø§Ø±Ø´ ØªØ¬Ù‡ÛŒØ²Ø§Øª"
        if not use_persian:
            title_str = translations.get(title_str, title_str)
        generate_pdf(title_str, elements, buffer)

        # ğŸ‘ˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø§ getvalue() Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†
        pdf_data = buffer.getvalue()
        st.download_button(
            label="â¬‡ï¸ Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF",
            data=pdf_data,
            file_name="Ú¯Ø²Ø§Ø±Ø´_ØªØ¬Ù‡ÛŒØ²Ø§Øª.pdf",
            mime="application/pdf"
        )
        
        # Ú†Ú© ÙÙˆÙ†Øª
        if not available_fonts:
            st.warning("âš ï¸ ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. PDF Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯.")

# ----------- Tab6: Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ -----------
with tab6:
    st.subheader("ğŸ”® Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…ØµØ±Ù ØªØ¬Ù‡ÛŒØ²Ø§Øª")
    if columns:
        forecast_col = st.selectbox("ğŸ“Œ Ø§Ù†ØªØ®Ø§Ø¨ ØªØ¬Ù‡ÛŒØ² Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ:", columns)
        
        time_granularity_pred = st.radio("â±ï¸ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ù†Ù…Ø§ÛŒØ´:", ["Ø±ÙˆØ²Ø§Ù†Ù‡", "Ù…Ø§Ù‡Ø§Ù†Ù‡", "Ø³Ø§Ù„ÛŒØ§Ù†Ù‡"], key="pred_radio")
        
        df_pred = filtered_df.dropna(subset=[forecast_col]).copy()
        if len(df_pred) > 1:
            df_pred["Ø±ÙˆØ²"] = (df_pred["ØªØ§Ø±ÛŒØ®"] - df_pred["ØªØ§Ø±ÛŒØ®"].min()).dt.days
            X = df_pred[["Ø±ÙˆØ²"]].values
            y = df_pred[forecast_col].values
            model = LinearRegression().fit(X, y)
            
            future_days = np.arange(X.max()+1, X.max()+31).reshape(-1,1)
            future_pred = model.predict(future_days)
            future_dates = pd.date_range(df_pred["ØªØ§Ø±ÛŒØ®"].max()+pd.Timedelta(days=1), periods=30)
            
            if time_granularity_pred == "Ø±ÙˆØ²Ø§Ù†Ù‡":
                df_pred["ØªØ§Ø±ÛŒØ® Ù†Ù…Ø§ÛŒØ´"] = df_pred["ØªØ§Ø±ÛŒØ®"].map(lambda x: JalaliDate(x).strftime('%Y/%m/%d'))
                future_dates_sh = [JalaliDate(d).strftime('%Y/%m/%d') for d in future_dates]
            elif time_granularity_pred == "Ù…Ø§Ù‡Ø§Ù†Ù‡":
                df_pred["ØªØ§Ø±ÛŒØ® Ù†Ù…Ø§ÛŒØ´"] = df_pred["ØªØ§Ø±ÛŒØ®"].map(lambda x: JalaliDate(x).strftime('%Y/%m'))
                df_pred = df_pred.groupby("ØªØ§Ø±ÛŒØ® Ù†Ù…Ø§ÛŒØ´")[forecast_col].sum().reset_index()
                future_dates_sh = [JalaliDate(d).strftime('%Y/%m') for d in future_dates]
            elif time_granularity_pred == "Ø³Ø§Ù„ÛŒØ§Ù†Ù‡":
                df_pred["ØªØ§Ø±ÛŒØ® Ù†Ù…Ø§ÛŒØ´"] = df_pred["ØªØ§Ø±ÛŒØ®"].map(lambda x: JalaliDate(x).strftime('%Y'))
                df_pred = df_pred.groupby("ØªØ§Ø±ÛŒØ® Ù†Ù…Ø§ÛŒØ´")[forecast_col].sum().reset_index()
                future_dates_sh = [JalaliDate(d).strftime('%Y') for d in future_dates]
            
            fig_forecast = go.Figure()
            fig_forecast.add_trace(go.Scatter(
                x=df_pred["ØªØ§Ø±ÛŒØ® Ù†Ù…Ø§ÛŒØ´"],
                y=df_pred[forecast_col],
                mode="lines+markers",
                name="Ø¯Ø§Ø¯Ù‡ ÙˆØ§Ù‚Ø¹ÛŒ"
            ))
            fig_forecast.add_trace(go.Scatter(
                x=future_dates_sh,
                y=future_pred,
                mode="lines+markers",
                name="Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ"
            ))
            fig_forecast.update_layout(
                title="Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…ØµØ±Ù Ø¨Ø±Ù‚",
                xaxis_title="ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ",
                yaxis_title="Ù…ØµØ±Ù (MWh)",
                xaxis_tickangle=-45
            )
            st.plotly_chart(fig_forecast, use_container_width=True)

            # Ø®Ø±ÙˆØ¬ÛŒ PDF Ø¨Ø±Ø§ÛŒ Tab6
            if st.button("â¬‡ï¸ Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF Tab6"):
                buffer = io.BytesIO()
                elements = []
                
                data = [df_pred.columns.tolist()] + df_pred.values.tolist()
                
                # ØªØ±Ø¬Ù…Ù‡ Ù‡Ø¯Ø±Ù‡Ø§ Ø§Ú¯Ø± Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
                translations_local = {
                    "ØªØ§Ø±ÛŒØ® Ù†Ù…Ø§ÛŒØ´": "Display Date",
                    forecast_col: "Consumption"
                }
                use_persian = available_fonts and font_name != "Helvetica"
                if not use_persian and data and isinstance(data[0], list) and len(data[0]) >= 2:
                    data[0][0] = translations_local.get(data[0][0], data[0][0])
                    data[0][1] = translations_local.get(data[0][1], data[0][1])
                
                # Reshape Ù…ØªÙ†â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ RTL Ø§Ú¯Ø± ÙØ§Ø±Ø³ÛŒ (ÙÙ‚Ø· Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§)
                if use_persian:
                    try:
                        import arabic_reshaper
                        from bidi.algorithm import get_display
                        for row in data:
                            for i, cell in enumerate(row):
                                if isinstance(cell, str):
                                    row[i] = get_display(arabic_reshaper.reshape(cell))
                    except ImportError:
                        st.warning("Ø¨Ø±Ø§ÛŒ RTL Ø¯Ø± Ø¬Ø¯ÙˆÙ„ØŒ arabic-reshaper Ùˆ python-bidi Ø±Ùˆ Ù†ØµØ¨ Ú©Ù†.")
                
                table = Table(data)
                table.setStyle(TableStyle([
                    ('BACKGROUND', (0,0), (-1,0), colors.lightgrey),  # Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ø¹Ù†ÙˆØ§Ù†
                    ('TEXTCOLOR', (0,0), (-1,0), colors.black),       # Ù…ØªÙ† Ø¹Ù†ÙˆØ§Ù†
                    ('GRID', (0,0), (-1,-1), 0.5, colors.lightgrey),  # ğŸ‘ˆ grid Ú©Ù…â€ŒØ±Ù†Ú¯ (Ù†Ù‡ Ù…Ø´Ú©ÛŒ)
                    ('ALIGN', (0,0), (-1,-1), 'CENTER')
                ]))
                elements.append(table)
                
                # ØªÙˆÙ„ÛŒØ¯ ØªØµÙˆÛŒØ± Ø¨Ø§ Ú©ÛŒÙÛŒØª Ø¨Ù‡ØªØ± (Ù†ÛŒØ§Ø² Ø¨Ù‡ kaleido: pip install kaleido)
                img_buf = io.BytesIO()
                fig_forecast.write_image(img_buf, format='png', width=800, height=400, scale=2)
                img_buf.seek(0)
                elements.append(Image(img_buf, width=500, height=300))
                
                title = "Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…ØµØ±Ù ØªØ¬Ù‡ÛŒØ²Ø§Øª"
                if not use_persian:
                    title = translations.get(title, title)
                generate_pdf(title, elements, buffer)
                
                # ğŸ‘ˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø§ getvalue() Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†
                pdf_data = buffer.getvalue()
                st.download_button(
                    label="Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF",
                    data=pdf_data,
                    file_name="tab6.pdf",
                    mime="application/pdf"
                )
                
                # Ú†Ú© ÙÙˆÙ†Øª
                if not available_fonts:
                    st.warning("âš ï¸ ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. PDF Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯.")

# ----------- Tab7: KPI Ù¾ÛŒØ´Ø±ÙØªÙ‡ -----------
with tab7:
    st.markdown("## âœ¨ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ (KPI Ù¾ÛŒØ´Ø±ÙØªÙ‡)")

    kpi_columns = st.multiselect(
        "ğŸ“Œ Ø§Ù†ØªØ®Ø§Ø¨ ØªØ¬Ù‡ÛŒØ²Ø§Øª Ø¨Ø±Ø§ÛŒ KPI:", 
        columns, 
        default=columns[:3] if columns else []
    )

    if kpi_columns:
        st.markdown("### ğŸ”¹ Ú©Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ KPI")
        kpis = []
        for col in kpi_columns:
            total = filtered_df[col].sum()
            avg = filtered_df[col].mean()
            max_val = filtered_df[col].max()
            kpis.append((col, total, avg, max_val))

        for col_name, total, avg, max_val in kpis:
            st.markdown(f"#### ØªØ¬Ù‡ÛŒØ²Ø§Øª: {col_name}")
            c1, c2, c3 = st.columns(3)
            with c1:
                st.metric(f"ğŸ”Œ Ù…Ø¬Ù…ÙˆØ¹ Ù…ØµØ±Ù", f"{total:,.0f} MWh")
            with c2:
                st.metric(f"ğŸ“Š Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØµØ±Ù", f"{avg:,.2f} MWh")
            with c3:
                st.metric(f"ğŸš€ Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ù…ØµØ±Ù", f"{max_val:,.0f} MWh")
            st.markdown("---")

        st.markdown("### ğŸ“ Ù…ØµØ±Ù Ù…ØªÙˆØ³Ø· Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ")
        period_option = st.radio("â±ï¸ Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ø§Ø²Ù‡:", ["Ø±ÙˆØ²Ø§Ù†Ù‡", "Ù…Ø§Ù‡Ø§Ù†Ù‡", "Ø³Ø§Ù„ÛŒØ§Ù†Ù‡"], horizontal=True)

        df_avg = filtered_df.copy()
        if period_option == "Ø±ÙˆØ²Ø§Ù†Ù‡":
            df_avg["ØªØ§Ø±ÛŒØ® Ù†Ù…Ø§ÛŒØ´"] = df_avg["ØªØ§Ø±ÛŒØ®"]
        elif period_option == "Ù…Ø§Ù‡Ø§Ù†Ù‡":
            df_avg["ØªØ§Ø±ÛŒØ® Ù†Ù…Ø§ÛŒØ´"] = df_avg["ØªØ§Ø±ÛŒØ®"].map(lambda x: JalaliDate(x).strftime('%Y/%m'))
        else:
            df_avg["ØªØ§Ø±ÛŒØ® Ù†Ù…Ø§ÛŒØ´"] = df_avg["ØªØ§Ø±ÛŒØ®"].map(lambda x: JalaliDate(x).strftime('%Y'))

        df_avg_grouped = df_avg.groupby("ØªØ§Ø±ÛŒØ® Ù†Ù…Ø§ÛŒØ´")[kpi_columns].mean().reset_index()
        fig_avg = px.line(
            df_avg_grouped,
            x="ØªØ§Ø±ÛŒØ® Ù†Ù…Ø§ÛŒØ´",
            y=kpi_columns,
            markers=True,
            title=f"ğŸ“Š Ù…ØµØ±Ù Ù…ØªÙˆØ³Ø· {period_option}",
            template="plotly_white"
        )
        fig_avg.update_layout(
            xaxis_title="ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ",
            yaxis_title="Ù…ØµØ±Ù Ù…ØªÙˆØ³Ø· (MWh)",
            legend_title="ØªØ¬Ù‡ÛŒØ²Ø§Øª"
        )
        st.plotly_chart(fig_avg, use_container_width=True)

        # Ø®Ø±ÙˆØ¬ÛŒ PDF Ø¨Ø±Ø§ÛŒ Tab7
        if st.button("â¬‡ï¸ Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF Tab7"):
            buffer = io.BytesIO()
            elements = []
            
            kpi_data = [['ØªØ¬Ù‡ÛŒØ²', 'Ù…Ø¬Ù…ÙˆØ¹', 'Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†', 'Ø¨ÛŒØ´ØªØ±ÛŒÙ†']]
            for col_name, total, avg, max_val in kpis:
                kpi_data.append([col_name, f"{total:,.0f}", f"{avg:,.2f}", f"{max_val:,.0f}"])
            
            # ØªØ±Ø¬Ù…Ù‡ Ù‡Ø¯Ø±Ù‡Ø§ Ø§Ú¯Ø± Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
            translations_local = {
                "ØªØ¬Ù‡ÛŒØ²": "Equipment",
                "Ù…Ø¬Ù…ÙˆØ¹": "Total",
                "Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†": "Average",
                "Ø¨ÛŒØ´ØªØ±ÛŒÙ†": "Max"
            }
            use_persian = available_fonts and font_name != "Helvetica"
            if not use_persian and kpi_data and isinstance(kpi_data[0], list) and len(kpi_data[0]) >= 4:
                kpi_data[0][0] = translations_local.get(kpi_data[0][0], kpi_data[0][0])
                kpi_data[0][1] = translations_local.get(kpi_data[0][1], kpi_data[0][1])
                kpi_data[0][2] = translations_local.get(kpi_data[0][2], kpi_data[0][2])
                kpi_data[0][3] = translations_local.get(kpi_data[0][3], kpi_data[0][3])
            
            # Reshape Ù…ØªÙ†â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ RTL Ø§Ú¯Ø± ÙØ§Ø±Ø³ÛŒ (ÙÙ‚Ø· Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§)
            if use_persian:
                try:
                    import arabic_reshaper
                    from bidi.algorithm import get_display
                    for row in kpi_data:
                        for i, cell in enumerate(row):
                            if isinstance(cell, str):
                                row[i] = get_display(arabic_reshaper.reshape(cell))
                except ImportError:
                    st.warning("Ø¨Ø±Ø§ÛŒ RTL Ø¯Ø± Ø¬Ø¯ÙˆÙ„ØŒ arabic-reshaper Ùˆ python-bidi Ø±Ùˆ Ù†ØµØ¨ Ú©Ù†.")
            
            table = Table(kpi_data)
            table.setStyle(TableStyle([
                ('BACKGROUND', (0,0), (-1,0), colors.lightgrey),  # Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ø¹Ù†ÙˆØ§Ù†
                ('TEXTCOLOR', (0,0), (-1,0), colors.black),       # Ù…ØªÙ† Ø¹Ù†ÙˆØ§Ù†
                ('GRID', (0,0), (-1,-1), 0.5, colors.lightgrey),  # ğŸ‘ˆ grid Ú©Ù…â€ŒØ±Ù†Ú¯ (Ù†Ù‡ Ù…Ø´Ú©ÛŒ)
                ('ALIGN', (0,0), (-1,-1), 'CENTER')
            ]))
            elements.append(table)
            
            # ØªÙˆÙ„ÛŒØ¯ ØªØµÙˆÛŒØ± Ø¨Ø§ Ú©ÛŒÙÛŒØª Ø¨Ù‡ØªØ± (Ù†ÛŒØ§Ø² Ø¨Ù‡ kaleido: pip install kaleido)
            img_buf = io.BytesIO()
            fig_avg.write_image(img_buf, format='png', width=800, height=400, scale=2)
            img_buf.seek(0)
            elements.append(Image(img_buf, width=500, height=300))
            
            title = "KPI Ù¾ÛŒØ´Ø±ÙØªÙ‡"
            if not use_persian:
                title = translations.get(title, title)
            generate_pdf(title, elements, buffer)
            
            # ğŸ‘ˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø§ getvalue() Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†
            pdf_data = buffer.getvalue()
            st.download_button(
                label="Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF",
                data=pdf_data,
                file_name="tab7.pdf",
                mime="application/pdf"
            )
            
            # Ú†Ú© ÙÙˆÙ†Øª
            if not available_fonts:
                st.warning("âš ï¸ ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. PDF Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯.")
    else:
        st.warning("âš ï¸ Ù‡ÛŒÚ† ØªØ¬Ù‡ÛŒØ²ÛŒ Ø¨Ø±Ø§ÛŒ KPI Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")

# ----------- Tab8: ØªØ­Ù„ÛŒÙ„ Ø±ÙˆÙ†Ø¯ ØªØºÛŒÛŒØ±Ø§Øª -----------
with tab8:
    st.subheader("ğŸ“ˆ ØªØºÛŒÛŒØ±Ø§Øª Ø¯Ø±ØµØ¯ÛŒ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ø¯ÙˆØ±Ù‡ Ù‚Ø¨Ù„ÛŒ")

    selected_col = st.selectbox("ğŸ”Œ Ø§Ù†ØªØ®Ø§Ø¨ ØªØ¬Ù‡ÛŒØ²:", columns)

    period_type = st.radio("â±ï¸ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ:", ["Ø±ÙˆØ²Ø§Ù†Ù‡", "Ù…Ø§Ù‡Ø§Ù†Ù‡", "Ø³Ø§Ù„ÛŒØ§Ù†Ù‡"])

    if selected_col:
        df_change = filtered_df.copy()

        if period_type == "Ø±ÙˆØ²Ø§Ù†Ù‡":
            df_change["period"] = df_change["ØªØ§Ø±ÛŒØ®"].dt.to_period("D").dt.to_timestamp()
        elif period_type == "Ù…Ø§Ù‡Ø§Ù†Ù‡":
            df_change["period"] = df_change["ØªØ§Ø±ÛŒØ®"].dt.to_period("M").dt.to_timestamp(how="end")
        elif period_type == "Ø³Ø§Ù„ÛŒØ§Ù†Ù‡":
            df_change["period"] = df_change["ØªØ§Ø±ÛŒØ®"].dt.to_period("Y").dt.to_timestamp()

        df_change = df_change.groupby("period")[selected_col].sum().reset_index()

        df_change["ØªØ§Ø±ÛŒØ® Ù†Ù…Ø§ÛŒØ´"] = df_change["period"].apply(
            lambda x: JalaliDate(pd.to_datetime(x)).strftime('%Y/%m/%d')
        )

        df_change["Ø¯Ø±ØµØ¯ ØªØºÛŒÛŒØ±"] = df_change[selected_col].pct_change() * 100

        df_change.replace([np.inf, -np.inf], np.nan, inplace=True)

        df_change["Ø¯Ø±ØµØ¯ ØªØºÛŒÛŒØ±"] = df_change["Ø¯Ø±ØµØ¯ ØªØºÛŒÛŒØ±"].fillna(0).astype(float)

        if not df_change.empty:
            st.markdown("ğŸ“‹ **Ø¬Ø¯ÙˆÙ„ ØªØºÛŒÛŒØ±Ø§Øª Ø¯Ø±ØµØ¯ÛŒ**")
            st.dataframe(
                df_change[["ØªØ§Ø±ÛŒØ® Ù†Ù…Ø§ÛŒØ´", selected_col, "Ø¯Ø±ØµØ¯ ØªØºÛŒÛŒØ±"]].round(2),
                use_container_width=True
            )

            fig_line = px.line(
                df_change,
                x="ØªØ§Ø±ÛŒØ® Ù†Ù…Ø§ÛŒØ´",
                y="Ø¯Ø±ØµØ¯ ØªØºÛŒÛŒØ±",
                title=f"ğŸ“ˆ ØªØºÛŒÛŒØ±Ø§Øª Ø¯Ø±ØµØ¯ÛŒ {selected_col} ({period_type})",
                markers=True,
                template="plotly_white"
            )
            fig_line.update_layout(yaxis_title="Ø¯Ø±ØµØ¯ ØªØºÛŒÛŒØ± (%)", xaxis_title="ØªØ§Ø±ÛŒØ®")
            st.plotly_chart(fig_line, use_container_width=True)

            measures = ["relative"] * len(df_change)
            measures[-1] = "total"

            y_values = df_change["Ø¯Ø±ØµØ¯ ØªØºÛŒÛŒØ±"].tolist()
            x_values = df_change["ØªØ§Ø±ÛŒØ® Ù†Ù…Ø§ÛŒØ´"].tolist()

            fig_wf = go.Figure(go.Waterfall(
                name="Ø¯Ø±ØµØ¯ ØªØºÛŒÛŒØ±",
                orientation="v",
                measure=measures,
                x=x_values,
                y=y_values,
                decreasing=dict(marker=dict(color="red")),
                increasing=dict(marker=dict(color="green")),
                totals=dict(marker=dict(color="blue")),
                text=[f"{v:.2f}%" for v in y_values],
                textposition="outside",
            ))

            fig_wf.update_layout(
                title=f"ğŸ’§ Ù†Ù…ÙˆØ¯Ø§Ø± Waterfall ØªØºÛŒÛŒØ±Ø§Øª Ø¯Ø±ØµØ¯ÛŒ {selected_col} ({period_type})",
                yaxis_title="Ø¯Ø±ØµØ¯ ØªØºÛŒÛŒØ± (%)",
                xaxis_title="ØªØ§Ø±ÛŒØ®"
            )
            st.plotly_chart(fig_wf, use_container_width=True)

            idx_max = df_change["Ø¯Ø±ØµØ¯ ØªØºÛŒÛŒØ±"].idxmax()
            idx_min = df_change["Ø¯Ø±ØµØ¯ ØªØºÛŒÛŒØ±"].idxmin()
            max_increase = df_change.loc[idx_max]
            max_decrease = df_change.loc[idx_min]
            st.markdown(
                f"**Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ:**\n\n"
                f"ğŸ”º Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ø§ÙØ²Ø§ÛŒØ´ Ù…ØµØ±Ù **{selected_col}**: "
                f"**{max_increase['Ø¯Ø±ØµØ¯ ØªØºÛŒÛŒØ±']:.2f}%** Ø¯Ø± Ø¯ÙˆØ±Ù‡ **{max_increase['ØªØ§Ø±ÛŒØ® Ù†Ù…Ø§ÛŒØ´']}**\n\n"
                f"ğŸ”» Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ú©Ø§Ù‡Ø´ Ù…ØµØ±Ù **{selected_col}**: "
                f"**{max_decrease['Ø¯Ø±ØµØ¯ ØªØºÛŒÛŒØ±']:.2f}%** Ø¯Ø± Ø¯ÙˆØ±Ù‡ **{max_decrease['ØªØ§Ø±ÛŒØ® Ù†Ù…Ø§ÛŒØ´']}**"
            )

            # Ø®Ø±ÙˆØ¬ÛŒ PDF Ø¨Ø±Ø§ÛŒ Tab8
            if st.button("â¬‡ï¸ Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF Tab8"):
                buffer = io.BytesIO()
                elements = []
                
                data = [df_change[["ØªØ§Ø±ÛŒØ® Ù†Ù…Ø§ÛŒØ´", selected_col, "Ø¯Ø±ØµØ¯ ØªØºÛŒÛŒØ±"]].columns.tolist()] + df_change[["ØªØ§Ø±ÛŒØ® Ù†Ù…Ø§ÛŒØ´", selected_col, "Ø¯Ø±ØµØ¯ ØªØºÛŒÛŒØ±"]].round(2).values.tolist()
                
                # ØªØ±Ø¬Ù…Ù‡ Ù‡Ø¯Ø±Ù‡Ø§ Ø§Ú¯Ø± Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
                translations_local = {
                    "ØªØ§Ø±ÛŒØ® Ù†Ù…Ø§ÛŒØ´": "Display Date",
                    selected_col: "Consumption",
                    "Ø¯Ø±ØµØ¯ ØªØºÛŒÛŒØ±": "Percent Change"
                }
                use_persian = available_fonts and font_name != "Helvetica"
                if not use_persian and data and isinstance(data[0], list) and len(data[0]) >= 3:
                    data[0][0] = translations_local.get(data[0][0], data[0][0])
                    data[0][1] = translations_local.get(data[0][1], data[0][1])
                    data[0][2] = translations_local.get(data[0][2], data[0][2])
                
                # Reshape Ù…ØªÙ†â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ RTL Ø§Ú¯Ø± ÙØ§Ø±Ø³ÛŒ (ÙÙ‚Ø· Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§)
                if use_persian:
                    try:
                        import arabic_reshaper
                        from bidi.algorithm import get_display
                        for row in data:
                            for i, cell in enumerate(row):
                                if isinstance(cell, str):
                                    row[i] = get_display(arabic_reshaper.reshape(cell))
                    except ImportError:
                        st.warning("Ø¨Ø±Ø§ÛŒ RTL Ø¯Ø± Ø¬Ø¯ÙˆÙ„ØŒ arabic-reshaper Ùˆ python-bidi Ø±Ùˆ Ù†ØµØ¨ Ú©Ù†.")
                
                table = Table(data)
                table.setStyle(TableStyle([
                    ('BACKGROUND', (0,0), (-1,0), colors.lightgrey),  # Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ø¹Ù†ÙˆØ§Ù†
                    ('TEXTCOLOR', (0,0), (-1,0), colors.black),       # Ù…ØªÙ† Ø¹Ù†ÙˆØ§Ù†
                    ('GRID', (0,0), (-1,-1), 0.5, colors.lightgrey),  # ğŸ‘ˆ grid Ú©Ù…â€ŒØ±Ù†Ú¯ (Ù†Ù‡ Ù…Ø´Ú©ÛŒ)
                    ('ALIGN', (0,0), (-1,-1), 'CENTER')
                ]))
                elements.append(table)
                
                # ØªÙˆÙ„ÛŒØ¯ ØªØµÙˆÛŒØ± Ø¨Ø§ Ú©ÛŒÙÛŒØª Ø¨Ù‡ØªØ± (Ù†ÛŒØ§Ø² Ø¨Ù‡ kaleido: pip install kaleido)
                img_buf1 = io.BytesIO()
                fig_line.write_image(img_buf1, format='png', width=800, height=400, scale=2)
                img_buf1.seek(0)
                elements.append(Image(img_buf1, width=500, height=300))
                
                img_buf2 = io.BytesIO()
                fig_wf.write_image(img_buf2, format='png', width=800, height=400, scale=2)
                img_buf2.seek(0)
                elements.append(Image(img_buf2, width=500, height=300))
                
                title = "ØªØ­Ù„ÛŒÙ„ Ø±ÙˆÙ†Ø¯ ØªØºÛŒÛŒØ±Ø§Øª"
                if not use_persian:
                    title = translations.get(title, title)
                generate_pdf(title, elements, buffer)
                
                # ğŸ‘ˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø§ getvalue() Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†
                pdf_data = buffer.getvalue()
                st.download_button(
                    label="Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF",
                    data=pdf_data,
                    file_name="tab8.pdf",
                    mime="application/pdf"
                )
                
                # Ú†Ú© ÙÙˆÙ†Øª
                if not available_fonts:
                    st.warning("âš ï¸ ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. PDF Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯.")
        else:
            st.warning("ğŸ“­ Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")

# ----------- Tab9: Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ML -----------
with tab9:
    st.subheader("ğŸ¤– Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…ØµØ±Ù ØªØ¬Ù‡ÛŒØ²Ø§Øª Ø¨Ø§ Machine Learning")

    selected_cols = st.multiselect("ğŸ”Œ Ø§Ù†ØªØ®Ø§Ø¨ ØªØ¬Ù‡ÛŒØ²Ø§Øª (ML):", columns, key="ml_multiselect")

    if selected_cols:
        start_date = st.date_input("ğŸ“… Ø´Ø±ÙˆØ¹ Ø¨Ø§Ø²Ù‡ (ML)", value=filtered_df['ØªØ§Ø±ÛŒØ®'].min(), key="ml_start_date")
        end_date = st.date_input("ğŸ“… Ù¾Ø§ÛŒØ§Ù† Ø¨Ø§Ø²Ù‡ (ML)", value=filtered_df['ØªØ§Ø±ÛŒØ®'].max(), key="ml_end_date")

        df_ml = filtered_df[(filtered_df['ØªØ§Ø±ÛŒØ®'] >= pd.to_datetime(start_date)) &
                            (filtered_df['ØªØ§Ø±ÛŒØ®'] <= pd.to_datetime(end_date))].copy()

        error_table = []

        for col in selected_cols:
            st.markdown(f"### ğŸ”¹ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ {col}")

            ts = df_ml[['ØªØ§Ø±ÛŒØ®', col]].rename(columns={'ØªØ§Ø±ÛŒØ®': 'ds', col: 'y'}).dropna()
            ts['ds'] = pd.to_datetime(ts['ds'])
            ts = ts.sort_values('ds').reset_index(drop=True)

            if len(ts) < 4:
                st.warning(f"Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ {col} Ú©Ø§ÙÛŒ Ù†ÛŒØ³Øª (Ø­Ø¯Ø§Ù‚Ù„ 4 Ø±Ú©ÙˆØ±Ø¯ Ù„Ø§Ø²Ù… Ø§Ø³Øª).")
                continue

            train_size = int(len(ts) * 0.8)
            if train_size < 1:
                train_size = len(ts) - 1
            train_df = ts.iloc[:train_size].copy().reset_index(drop=True)
            test_df = ts.iloc[train_size:].copy().reset_index(drop=True)

            preds_prophet_test = pd.DataFrame(columns=['ds', 'Predicted', 'Lower', 'Upper'])
            preds_arima_test = pd.DataFrame(columns=['ds', 'Predicted', 'Lower', 'Upper'])
            preds_exp_test = pd.DataFrame(columns=['ds', 'Predicted', 'Lower', 'Upper'])
            df_pred_future_prophet = pd.DataFrame(columns=['ds', 'Predicted', 'Lower', 'Upper'])
            df_pred_future_arima = pd.DataFrame(columns=['ds', 'Predicted', 'Lower', 'Upper'])
            df_pred_future_exp = pd.DataFrame(columns=['ds', 'Predicted', 'Lower', 'Upper'])

            try:
                from prophet import Prophet
                m = Prophet(daily_seasonality=True)
                m.fit(train_df)

                future_test = test_df[['ds']].copy()
                forecast_test = m.predict(future_test)
                preds_prophet_test = forecast_test[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].rename(
                    columns={'yhat': 'Predicted', 'yhat_lower': 'Lower', 'yhat_upper': 'Upper'}
                )

                merged_p = test_df.merge(preds_prophet_test, on='ds', how='left')
                valid_p = merged_p.dropna(subset=['y', 'Predicted'])
                mae_prophet = valid_p['y'].sub(valid_p['Predicted']).abs().mean() if len(valid_p) > 0 else float('nan')
                rmse_prophet = ((valid_p['y'] - valid_p['Predicted'])**2).mean()**0.5 if len(valid_p) > 0 else float('nan')
            except Exception as e:
                mae_prophet = rmse_prophet = float('nan')
                st.error(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Prophet Ø¨Ø±Ø§ÛŒ {col}: {e}")

            try:
                from statsmodels.tsa.arima.model import ARIMA
                ts_arima_train = train_df.set_index('ds')['y']
                arima_model = ARIMA(ts_arima_train, order=(1,1,1))
                arima_fit = arima_model.fit()

                if len(test_df) > 0:
                    forecast_test_a = arima_fit.get_forecast(steps=len(test_df))
                    conf_int = forecast_test_a.conf_int(alpha=0.05)
                    preds_arima_test = pd.DataFrame({
                        'ds': test_df['ds'].values,
                        'Predicted': forecast_test_a.predicted_mean.values,
                        'Lower': conf_int.iloc[:, 0].values,
                        'Upper': conf_int.iloc[:, 1].values
                    })

                    merged_a = test_df.merge(preds_arima_test, on='ds', how='left')
                    valid_a = merged_a.dropna(subset=['y', 'Predicted'])
                    mae_arima = valid_a['y'].sub(valid_a['Predicted']).abs().mean() if len(valid_a) > 0 else float('nan')
                    rmse_arima = ((valid_a['y'] - valid_a['Predicted'])**2).mean()**0.5 if len(valid_a) > 0 else float('nan')
                else:
                    mae_arima = rmse_arima = float('nan')
            except Exception as e:
                mae_arima = rmse_arima = float('nan')
                st.error(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ ARIMA Ø¨Ø±Ø§ÛŒ {col}: {e}")

            try:
                from statsmodels.tsa.holtwinters import ExponentialSmoothing
                ts_exp_train = train_df.set_index('ds')['y']
                exp_model = ExponentialSmoothing(ts_exp_train, trend='add', seasonal=None, damped_trend=True)
                exp_fit = exp_model.fit()

                if len(test_df) > 0:
                    forecast_test_e = exp_fit.forecast(steps=len(test_df))
                    std_err = np.std(exp_fit.resid)
                    preds_exp_test = pd.DataFrame({
                        'ds': test_df['ds'].values,
                        'Predicted': forecast_test_e.values,
                        'Lower': forecast_test_e.values - 1.96 * std_err,
                        'Upper': forecast_test_e.values + 1.96 * std_err
                    })

                    merged_e = test_df.merge(preds_exp_test, on='ds', how='left')
                    valid_e = merged_e.dropna(subset=['y', 'Predicted'])
                    mae_exp = valid_e['y'].sub(valid_e['Predicted']).abs().mean() if len(valid_e) > 0 else float('nan')
                    rmse_exp = ((valid_e['y'] - valid_e['Predicted'])**2).mean()**0.5 if len(valid_e) > 0 else float('nan')
                else:
                    mae_exp = rmse_exp = float('nan')
            except Exception as e:
                mae_exp = rmse_exp = float('nan')
                st.error(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Exponential Smoothing Ø¨Ø±Ø§ÛŒ {col}: {e}")

            error_table.append([col, 'Prophet', round(mae_prophet, 2) if not pd.isna(mae_prophet) else None,
                                round(rmse_prophet, 2) if not pd.isna(rmse_prophet) else None])
            error_table.append([col, 'ARIMA', round(mae_arima, 2) if not pd.isna(mae_arima) else None,
                                round(rmse_arima, 2) if not pd.isna(rmse_arima) else None])
            error_table.append([col, 'ExponentialSmoothing', round(mae_exp, 2) if not pd.isna(mae_exp) else None,
                                round(rmse_exp, 2) if not pd.isna(rmse_exp) else None])

            rmse_candidates = {}
            if not pd.isna(rmse_prophet):
                rmse_candidates['Prophet'] = rmse_prophet
            if not pd.isna(rmse_arima):
                rmse_candidates['ARIMA'] = rmse_arima
            if not pd.isna(rmse_exp):
                rmse_candidates['ExponentialSmoothing'] = rmse_exp

            if rmse_candidates:
                best_model = min(rmse_candidates, key=rmse_candidates.get)
                best_rmse = rmse_candidates[best_model]
            else:
                best_model = None
                best_rmse = None

            try:
                m_full = Prophet(daily_seasonality=True)
                m_full.fit(ts)
                future_full = m_full.make_future_dataframe(periods=30)
                forecast_full = m_full.predict(future_full)
                df_pred_future_prophet = forecast_full[forecast_full['ds'] > ts['ds'].max()][['ds', 'yhat', 'yhat_lower', 'yhat_upper']].rename(
                    columns={'yhat': 'Predicted', 'yhat_lower': 'Lower', 'yhat_upper': 'Upper'}
                )
            except Exception:
                df_pred_future_prophet = pd.DataFrame(columns=['ds', 'Predicted', 'Lower', 'Upper'])

            try:
                ts_arima_full = ts.set_index('ds')['y']
                arima_full = ARIMA(ts_arima_full, order=(1,1,1))
                arima_full_fit = arima_full.fit()
                forecast_future_a = arima_full_fit.get_forecast(steps=30)
                conf_int_future = forecast_future_a.conf_int(alpha=0.05)
                df_pred_future_arima = pd.DataFrame({
                    'ds': pd.date_range(ts_arima_full.index[-1] + pd.Timedelta(days=1), periods=30),
                    'Predicted': forecast_future_a.predicted_mean.values,
                    'Lower': conf_int_future.iloc[:, 0].values,
                    'Upper': conf_int_future.iloc[:, 1].values
                })
            except Exception:
                df_pred_future_arima = pd.DataFrame(columns=['ds', 'Predicted', 'Lower', 'Upper'])

            try:
                ts_exp_full = ts.set_index('ds')['y']
                exp_full = ExponentialSmoothing(ts_exp_full, trend='add', seasonal=None, damped_trend=True)
                exp_full_fit = exp_full.fit()
                forecast_future_e = exp_full_fit.forecast(steps=30)
                std_err_full = np.std(exp_full_fit.resid)
                df_pred_future_exp = pd.DataFrame({
                    'ds': pd.date_range(ts_exp_full.index[-1] + pd.Timedelta(days=1), periods=30),
                    'Predicted': forecast_future_e.values,
                    'Lower': forecast_future_e.values - 1.96 * std_err_full,
                    'Upper': forecast_future_e.values + 1.96 * std_err_full
                })
            except Exception:
                df_pred_future_exp = pd.DataFrame(columns=['ds', 'Predicted', 'Lower', 'Upper'])

            fig = go.Figure()
            fig.add_trace(go.Scatter(x=ts['ds'], y=ts['y'], mode='lines+markers', name='Actual', line=dict(color='blue')))

            if not preds_prophet_test.empty:
                fig.add_trace(go.Scatter(x=preds_prophet_test['ds'], y=preds_prophet_test['Predicted'],
                                         mode='lines+markers', name='Prophet (Test)', line=dict(color='green')))
                fig.add_trace(go.Scatter(x=preds_prophet_test['ds'], y=preds_prophet_test['Lower'],
                                         mode='lines', name='Prophet Lower CI', line=dict(color='green', dash='dash')))
                fig.add_trace(go.Scatter(x=preds_prophet_test['ds'], y=preds_prophet_test['Upper'],
                                         mode='lines', name='Prophet Upper CI', line=dict(color='green', dash='dash'), fill='tonexty'))

            if not preds_arima_test.empty:
                fig.add_trace(go.Scatter(x=preds_arima_test['ds'], y=preds_arima_test['Predicted'],
                                         mode='lines+markers', name='ARIMA (Test)', line=dict(color='orange')))
                fig.add_trace(go.Scatter(x=preds_arima_test['ds'], y=preds_arima_test['Lower'],
                                         mode='lines', name='ARIMA Lower CI', line=dict(color='orange', dash='dash')))
                fig.add_trace(go.Scatter(x=preds_arima_test['ds'], y=preds_arima_test['Upper'],
                                         mode='lines', name='ARIMA Upper CI', line=dict(color='orange', dash='dash'), fill='tonexty'))

            if not preds_exp_test.empty:
                fig.add_trace(go.Scatter(x=preds_exp_test['ds'], y=preds_exp_test['Predicted'],
                                         mode='lines+markers', name='Exp Smoothing (Test)', line=dict(color='purple')))
                fig.add_trace(go.Scatter(x=preds_exp_test['ds'], y=preds_exp_test['Lower'],
                                         mode='lines', name='Exp Lower CI', line=dict(color='purple', dash='dash')))
                fig.add_trace(go.Scatter(x=preds_exp_test['ds'], y=preds_exp_test['Upper'],
                                         mode='lines', name='Exp Upper CI', line=dict(color='purple', dash='dash'), fill='tonexty'))

            if best_model == 'Prophet' and not df_pred_future_prophet.empty:
                fig.add_trace(go.Scatter(x=df_pred_future_prophet['ds'], y=df_pred_future_prophet['Predicted'],
                                         mode='lines+markers', name='Best (Future) - Prophet', line=dict(color='red', dash='dash')))
                fig.add_trace(go.Scatter(x=df_pred_future_prophet['ds'], y=df_pred_future_prophet['Lower'],
                                         mode='lines', name='Prophet Future Lower CI', line=dict(color='red', dash='dash')))
                fig.add_trace(go.Scatter(x=df_pred_future_prophet['ds'], y=df_pred_future_prophet['Upper'],
                                         mode='lines', name='Prophet Future Upper CI', line=dict(color='red', dash='dash'), fill='tonexty'))
            elif best_model == 'ARIMA' and not df_pred_future_arima.empty:
                fig.add_trace(go.Scatter(x=df_pred_future_arima['ds'], y=df_pred_future_arima['Predicted'],
                                         mode='lines+markers', name='Best (Future) - ARIMA', line=dict(color='red', dash='dash')))
                fig.add_trace(go.Scatter(x=df_pred_future_arima['ds'], y=df_pred_future_arima['Lower'],
                                         mode='lines', name='ARIMA Future Lower CI', line=dict(color='red', dash='dash')))
                fig.add_trace(go.Scatter(x=df_pred_future_arima['ds'], y=df_pred_future_arima['Upper'],
                                         mode='lines', name='ARIMA Future Upper CI', line=dict(color='red', dash='dash'), fill='tonexty'))
            elif best_model == 'ExponentialSmoothing' and not df_pred_future_exp.empty:
                fig.add_trace(go.Scatter(x=df_pred_future_exp['ds'], y=df_pred_future_exp['Predicted'],
                                         mode='lines+markers', name='Best (Future) - Exp', line=dict(color='red', dash='dash')))
                fig.add_trace(go.Scatter(x=df_pred_future_exp['ds'], y=df_pred_future_exp['Lower'],
                                         mode='lines', name='Exp Future Lower CI', line=dict(color='red', dash='dash')))
                fig.add_trace(go.Scatter(x=df_pred_future_exp['ds'], y=df_pred_future_exp['Upper'],
                                         mode='lines', name='Exp Future Upper CI', line=dict(color='red', dash='dash'), fill='tonexty'))

            fig.update_layout(
                title=f"ğŸ“ˆ Actual vs Predicted Ø¨Ø±Ø§ÛŒ {col}",
                xaxis_title="ØªØ§Ø±ÛŒØ®",
                yaxis_title="Ù…Ù‚Ø¯Ø§Ø± Ù…ØµØ±Ù",
                template="plotly_white"
            )
            st.plotly_chart(fig, use_container_width=True, key=f"ml_chart_{col}")

            if best_model is not None:
                st.success(f"ğŸ’¡ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„ Ø¨Ø±Ø§ÛŒ {col}: {best_model} (RMSE = {best_rmse:.2f})")
            else:
                st.info(f"âš ï¸ Ø¨Ø±Ø§ÛŒ {col} Ù…Ø¯Ù„ Ø¨Ø±ØªØ± Ù‚Ø§Ø¨Ù„ ØªØ¹ÛŒÛŒÙ† Ù†ÛŒØ³Øª (Ø®Ø·Ø§ ÛŒØ§ Ø¯Ø§Ø¯Ù‡Ù” Ù†Ø§Ú©Ø§ÙÛŒ).")

            # Ø®Ø±ÙˆØ¬ÛŒ PDF Ø¨Ø±Ø§ÛŒ Tab9 (Ø¨Ø±Ø§ÛŒ Ù‡Ø± ØªØ¬Ù‡ÛŒØ²)
            if st.button(f"â¬‡ï¸ Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF Ø¨Ø±Ø§ÛŒ {col}"):
                buffer = io.BytesIO()
                elements = []
                
                # ØªÙˆÙ„ÛŒØ¯ ØªØµÙˆÛŒØ± Ø¨Ø§ Ú©ÛŒÙÛŒØª Ø¨Ù‡ØªØ± (Ù†ÛŒØ§Ø² Ø¨Ù‡ kaleido: pip install kaleido)
                img_buf = io.BytesIO()
                fig.write_image(img_buf, format='png', width=800, height=400, scale=2)
                img_buf.seek(0)
                elements.append(Image(img_buf, width=500, height=300))
                
                title = f"Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ {col}"
                if not use_persian:
                    title = translations.get("Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ", "Forecast") + f" {col}"
                generate_pdf(title, elements, buffer)
                
                # ğŸ‘ˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø§ getvalue() Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†
                pdf_data = buffer.getvalue()
                st.download_button(
                    label="Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF",
                    data=pdf_data,
                    file_name=f"tab9_{col}.pdf",
                    mime="application/pdf"
                )
                
                # Ú†Ú© ÙÙˆÙ†Øª
                if not available_fonts:
                    st.warning("âš ï¸ ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. PDF Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯.")

        if error_table:
            st.markdown("### ğŸ“Š Ø¬Ø¯ÙˆÙ„ Ø®Ø·Ø§Ù‡Ø§ Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ ØªØ¬Ù‡ÛŒØ²Ø§Øª")
            error_df = pd.DataFrame(error_table, columns=['ØªØ¬Ù‡ÛŒØ²', 'Ù…Ø¯Ù„', 'MAE', 'RMSE'])
            st.dataframe(error_df.style.format({'MAE': '{:.2f}', 'RMSE': '{:.2f}'}))

            # Ø®Ø±ÙˆØ¬ÛŒ PDF Ø¨Ø±Ø§ÛŒ Ø¬Ø¯ÙˆÙ„ Ø®Ø·Ø§Ù‡Ø§
            if st.button("â¬‡ï¸ Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF Ø¬Ø¯ÙˆÙ„ Ø®Ø·Ø§Ù‡Ø§ Tab9"):
                buffer = io.BytesIO()
                elements = []
                
                data = [error_df.columns.tolist()] + error_df.values.tolist()
                
                # ØªØ±Ø¬Ù…Ù‡ Ù‡Ø¯Ø±Ù‡Ø§ Ø§Ú¯Ø± Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
                translations_local = {
                    "ØªØ¬Ù‡ÛŒØ²": "Equipment",
                    "Ù…Ø¯Ù„": "Model",
                    "MAE": "MAE",
                    "RMSE": "RMSE"
                }
                use_persian = available_fonts and font_name != "Helvetica"
                if not use_persian and data and isinstance(data[0], list) and len(data[0]) >= 4:
                    data[0][0] = translations_local.get(data[0][0], data[0][0])
                    data[0][1] = translations_local.get(data[0][1], data[0][1])
                    data[0][2] = translations_local.get(data[0][2], data[0][2])
                    data[0][3] = translations_local.get(data[0][3], data[0][3])
                
                # Reshape Ù…ØªÙ†â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ RTL Ø§Ú¯Ø± ÙØ§Ø±Ø³ÛŒ (ÙÙ‚Ø· Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§)
                if use_persian:
                    try:
                        import arabic_reshaper
                        from bidi.algorithm import get_display
                        for row in data:
                            for i, cell in enumerate(row):
                                if isinstance(cell, str):
                                    row[i] = get_display(arabic_reshaper.reshape(cell))
                    except ImportError:
                        st.warning("Ø¨Ø±Ø§ÛŒ RTL Ø¯Ø± Ø¬Ø¯ÙˆÙ„ØŒ arabic-reshaper Ùˆ python-bidi Ø±Ùˆ Ù†ØµØ¨ Ú©Ù†.")
                
                table = Table(data)
                table.setStyle(TableStyle([
                    ('BACKGROUND', (0,0), (-1,0), colors.lightgrey),  # Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ø¹Ù†ÙˆØ§Ù†
                    ('TEXTCOLOR', (0,0), (-1,0), colors.black),       # Ù…ØªÙ† Ø¹Ù†ÙˆØ§Ù†
                    ('GRID', (0,0), (-1,-1), 0.5, colors.lightgrey),  # ğŸ‘ˆ grid Ú©Ù…â€ŒØ±Ù†Ú¯ (Ù†Ù‡ Ù…Ø´Ú©ÛŒ)
                    ('ALIGN', (0,0), (-1,-1), 'CENTER')
                ]))
                elements.append(table)
                
                title = "Ø¬Ø¯ÙˆÙ„ Ø®Ø·Ø§Ù‡Ø§"
                if not use_persian:
                    title = translations.get(title, title)
                generate_pdf(title, elements, buffer)
                
                # ğŸ‘ˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø§ getvalue() Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†
                pdf_data = buffer.getvalue()
                st.download_button(
                    label="Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF",
                    data=pdf_data,
                    file_name="tab9_errors.pdf",
                    mime="application/pdf"
                )
                
                # Ú†Ú© ÙÙˆÙ†Øª
                if not available_fonts:
                    st.warning("âš ï¸ ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. PDF Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯.")

# ----------- Tab10: ØªØ­Ù„ÛŒÙ„ Ø¯ÛŒØªØ§ -----------
with tab10:
    st.subheader("ğŸ”¬ ØªØ­Ù„ÛŒÙ„ Ø¯ÛŒØªØ§ Ùˆ ØªØ¹ÛŒÛŒÙ† Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ ØªØ§Ø«ÛŒØ±Ú¯Ø°Ø§Ø±")

    target_var = st.selectbox("ğŸ“Œ Ø§Ù†ØªØ®Ø§Ø¨ Ù…ØªØºÛŒØ± ÙˆØ§Ø¨Ø³ØªÙ‡:", columns)
    predictor_vars = st.multiselect("ğŸ“Œ Ø§Ù†ØªØ®Ø§Ø¨ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø³ØªÙ‚Ù„:", [col for col in columns if col != target_var])

    if target_var and predictor_vars:
        df_selected = df[[target_var] + predictor_vars].dropna()

        if len(df_selected) < 2:
            st.warning("âš ï¸ Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ (Ø­Ø¯Ø§Ù‚Ù„ Û² Ø±Ú©ÙˆØ±Ø¯ Ù„Ø§Ø²Ù… Ø§Ø³Øª).")
        else:
            st.markdown("### ğŸ“Š Ù…Ø§ØªØ±ÛŒØ³ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ")
            corr = df_selected.corr()
            fig_corr = px.imshow(
                corr,
                text_auto=True,
                color_continuous_scale="RdBu_r",
                zmin=-1, zmax=1,
                title="Ù…Ø§ØªØ±ÛŒØ³ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ"
            )
            st.plotly_chart(fig_corr, use_container_width=True)

            st.markdown("**ğŸ’¡ ØªÙØ³ÛŒØ± Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ:**")
            for col in predictor_vars:
                r = corr.loc[target_var, col]
                if r > 0.7:
                    strength = "Ù‚ÙˆÛŒ"
                elif r > 0.5:
                    strength = "Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡"
                else:
                    strength = "Ø¶Ø¹ÛŒÙ"
                st.write(f"{col}: Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ø§ {target_var} = {r:.2f} â†’ {strength}")

            st.markdown("### ğŸ“ˆ ØªØ­Ù„ÛŒÙ„ Ø±Ú¯Ø±Ø³ÛŒÙˆÙ†")

            st.markdown("#### Ø±Ú¯Ø±Ø³ÛŒÙˆÙ† ØªÚ©â€ŒÙ…ØªØºÛŒØ±Ù‡")
            single_results = []
            for col in predictor_vars:
                X = df_selected[[col]].dropna()
                if len(X) < 2:
                    st.warning(f"âš ï¸ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ {col} Ú©Ø§ÙÛŒ Ù†ÛŒØ³Øª (Ø­Ø¯Ø§Ù‚Ù„ Û² Ø±Ú©ÙˆØ±Ø¯).")
                    continue
                X_const = sm.add_constant(X)
                y_temp = df_selected.loc[X.index, target_var]
                if len(y_temp) < 2 or X_const.shape[0] == 0:
                    st.warning(f"âš ï¸ X_const Ø®Ø§Ù„ÛŒ Ø¨Ø±Ø§ÛŒ {col}.")
                    continue
                try:
                    model = sm.OLS(y_temp, X_const).fit()
                    r2 = model.rsquared
                    p_val = model.pvalues[col] if col in model.pvalues else np.nan
                    significant = p_val < 0.05 and r2 > 0.75
                    single_results.append({
                        "Variable": col,
                        "RÂ²": r2,
                        "p-value": p_val,
                        "Impactful": "âœ…" if significant else "âŒ"
                    })
                except Exception as e:
                    st.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø±Ú¯Ø±Ø³ÛŒÙˆÙ† {col}: {e}")
                    continue
            
            if single_results:
                st.table(pd.DataFrame(single_results))
            else:
                st.info("Ù‡ÛŒÚ† Ø±Ú¯Ø±Ø³ÛŒÙˆÙ† Ù…ÙˆÙÙ‚ÛŒ Ø§Ø¬Ø±Ø§ Ù†Ø´Ø¯.")

            if len(predictor_vars) > 1:
                st.markdown("#### Ø±Ú¯Ø±Ø³ÛŒÙˆÙ† Ú†Ù†Ø¯Ù…ØªØºÛŒØ±Ù‡")
                X_multi = df_selected[predictor_vars].dropna()
                if len(X_multi) < 2:
                    st.warning("âš ï¸ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø±Ú¯Ø±Ø³ÛŒÙˆÙ† Ú†Ù†Ø¯Ù…ØªØºÛŒØ±Ù‡ Ú©Ø§ÙÛŒ Ù†ÛŒØ³Øª.")
                else:
                    X_multi_const = sm.add_constant(X_multi)
                    y_multi = df_selected.loc[X_multi.index, target_var]
                    if len(y_multi) < 2 or X_multi_const.shape[0] == 0:
                        st.warning("âš ï¸ X_multi_const Ø®Ø§Ù„ÛŒ.")
                    else:
                        try:
                            multi_model = sm.OLS(y_multi, X_multi_const).fit()
                            multi_summary = pd.DataFrame({
                                "Variable": multi_model.params.index[1:],
                                "Coefficient": multi_model.params.values[1:],
                                "p-value": multi_model.pvalues.values[1:],
                                "Significant": ["âœ…" if p < 0.05 else "âŒ" for p in multi_model.pvalues.values[1:]]
                            })
                            st.table(multi_summary)
                        except Exception as e:
                            st.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø±Ú¯Ø±Ø³ÛŒÙˆÙ† Ú†Ù†Ø¯Ù…ØªØºÛŒØ±Ù‡: {e}")

            st.markdown("### ğŸ“¦ Ù†Ù…ÙˆØ¯Ø§Ø± Box Plot Ùˆ ØªØ¹ÛŒÛŒÙ† UCL/LCL")
            for col in predictor_vars + [target_var]:
                Q1 = df_selected[col].quantile(0.25)
                Q3 = df_selected[col].quantile(0.75)
                IQR = Q3 - Q1
                LCL = Q1 - 1.5 * IQR
                UCL = Q3 + 1.5 * IQR

                fig_box = px.box(df_selected, y=col, points="all", title=f"Box Plot: {col}")

                fig_box.add_hline(
                    y=UCL, line_dash="dash", line_color="red",
                    annotation_text=f"UCL = {UCL:.2f}", annotation_position="top right"
                )
                fig_box.add_hline(
                    y=LCL, line_dash="dash", line_color="green",
                    annotation_text=f"LCL = {LCL:.2f}", annotation_position="bottom right"
                )

                st.plotly_chart(fig_box, use_container_width=True)

                outliers = df_selected[(df_selected[col] > UCL) | (df_selected[col] < LCL)][col]
                if not outliers.empty:
                    st.markdown(
                        f"ğŸ” **ØªØ­Ù„ÛŒÙ„ {col}:**\n"
                        f"- Ù…Ù‚Ø¯Ø§Ø± **UCL** = {UCL:.2f}\n"
                        f"- Ù…Ù‚Ø¯Ø§Ø± **LCL** = {LCL:.2f}\n"
                        f"- ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ø±Ø¬ Ø§Ø² Ù…Ø­Ø¯ÙˆØ¯Ù‡ = {len(outliers)}\n"
                        f"- Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾Ø±Øª: {list(outliers.values)}"
                    )
                else:
                    st.markdown(
                        f"ğŸ” **ØªØ­Ù„ÛŒÙ„ {col}:**\n"
                        f"- Ù…Ù‚Ø¯Ø§Ø± **UCL** = {UCL:.2f}\n"
                        f"- Ù…Ù‚Ø¯Ø§Ø± **LCL** = {LCL:.2f}\n"
                        f"- Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø®Ø§Ø±Ø¬ Ø§Ø² Ù…Ø­Ø¯ÙˆØ¯Ù‡ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ âœ…"
                    )

            # Ø®Ø±ÙˆØ¬ÛŒ PDF Ø¨Ø±Ø§ÛŒ Tab10
            if st.button("â¬‡ï¸ Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF Tab10"):
                buffer = io.BytesIO()
                elements = []
                
                # ØªÙˆÙ„ÛŒØ¯ ØªØµÙˆÛŒØ± Ø¨Ø§ Ú©ÛŒÙÛŒØª Ø¨Ù‡ØªØ± (Ù†ÛŒØ§Ø² Ø¨Ù‡ kaleido: pip install kaleido)
                img_buf_corr = io.BytesIO()
                fig_corr.write_image(img_buf_corr, format='png', width=800, height=400, scale=2)
                img_buf_corr.seek(0)
                elements.append(Image(img_buf_corr, width=500, height=300))
                
                # Ø¬Ø¯ÙˆÙ„â€ŒÙ‡Ø§ÛŒ Ø±Ú¯Ø±Ø³ÛŒÙˆÙ†
                if single_results:
                    single_df = pd.DataFrame(single_results)
                    data_single = [single_df.columns.tolist()] + single_df.values.tolist()
                    
                    # ØªØ±Ø¬Ù…Ù‡ Ù‡Ø¯Ø±Ù‡Ø§ Ø§Ú¯Ø± Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
                    translations_local = {
                        "Variable": "Variable",
                        "RÂ²": "RÂ²",
                        "p-value": "p-value",
                        "Impactful": "Impactful"
                    }
                    use_persian = available_fonts and font_name != "Helvetica"
                    if not use_persian and data_single and isinstance(data_single[0], list):
                        for i, header in enumerate(data_single[0]):
                            data_single[0][i] = translations_local.get(header, header)
                    
                    # Reshape Ù…ØªÙ†â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ RTL Ø§Ú¯Ø± ÙØ§Ø±Ø³ÛŒ (ÙÙ‚Ø· Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§)
                    if use_persian:
                        try:
                            import arabic_reshaper
                            from bidi.algorithm import get_display
                            for row in data_single:
                                for i, cell in enumerate(row):
                                    if isinstance(cell, str):
                                        row[i] = get_display(arabic_reshaper.reshape(cell))
                        except ImportError:
                            st.warning("Ø¨Ø±Ø§ÛŒ RTL Ø¯Ø± Ø¬Ø¯ÙˆÙ„ØŒ arabic-reshaper Ùˆ python-bidi Ø±Ùˆ Ù†ØµØ¨ Ú©Ù†.")
                    
                    table_single = Table(data_single)
                    table_single.setStyle(TableStyle([
                        ('BACKGROUND', (0,0), (-1,0), colors.lightgrey),  # Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ø¹Ù†ÙˆØ§Ù†
                        ('TEXTCOLOR', (0,0), (-1,0), colors.black),       # Ù…ØªÙ† Ø¹Ù†ÙˆØ§Ù†
                        ('GRID', (0,0), (-1,-1), 0.5, colors.lightgrey),  # ğŸ‘ˆ grid Ú©Ù…â€ŒØ±Ù†Ú¯ (Ù†Ù‡ Ù…Ø´Ú©ÛŒ)
                        ('ALIGN', (0,0), (-1,-1), 'CENTER')
                    ]))
                    elements.append(table_single)
                
                if 'multi_summary' in locals():
                    data_multi = [multi_summary.columns.tolist()] + multi_summary.values.tolist()
                    
                    # ØªØ±Ø¬Ù…Ù‡ Ù‡Ø¯Ø±Ù‡Ø§ Ø§Ú¯Ø± Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
                    translations_local = {
                        "Variable": "Variable",
                        "Coefficient": "Coefficient",
                        "p-value": "p-value",
                        "Significant": "Significant"
                    }
                    if not use_persian and data_multi and isinstance(data_multi[0], list):
                        for i, header in enumerate(data_multi[0]):
                            data_multi[0][i] = translations_local.get(header, header)
                    
                    # Reshape Ù…ØªÙ†â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ RTL Ø§Ú¯Ø± ÙØ§Ø±Ø³ÛŒ (ÙÙ‚Ø· Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§)
                    if use_persian:
                        try:
                            import arabic_reshaper
                            from bidi.algorithm import get_display
                            for row in data_multi:
                                for i, cell in enumerate(row):
                                    if isinstance(cell, str):
                                        row[i] = get_display(arabic_reshaper.reshape(cell))
                        except ImportError:
                            st.warning("Ø¨Ø±Ø§ÛŒ RTL Ø¯Ø± Ø¬Ø¯ÙˆÙ„ØŒ arabic-reshaper Ùˆ python-bidi Ø±Ùˆ Ù†ØµØ¨ Ú©Ù†.")
                    
                    table_multi = Table(data_multi)
                    table_multi.setStyle(TableStyle([
                        ('BACKGROUND', (0,0), (-1,0), colors.lightgrey),  # Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ø¹Ù†ÙˆØ§Ù†
                        ('TEXTCOLOR', (0,0), (-1,0), colors.black),       # Ù…ØªÙ† Ø¹Ù†ÙˆØ§Ù†
                        ('GRID', (0,0), (-1,-1), 0.5, colors.lightgrey),  # ğŸ‘ˆ grid Ú©Ù…â€ŒØ±Ù†Ú¯ (Ù†Ù‡ Ù…Ø´Ú©ÛŒ)
                        ('ALIGN', (0,0), (-1,-1), 'CENTER')
                    ]))
                    elements.append(table_multi)
                
                # Box Plots
                for col in predictor_vars + [target_var]:
                    fig_box_col = px.box(df_selected, y=col, points="all", title=f"Box Plot: {col}")
                    img_buf_box = io.BytesIO()
                    fig_box_col.write_image(img_buf_box, format='png', width=800, height=400, scale=2)
                    img_buf_box.seek(0)
                    elements.append(Image(img_buf_box, width=500, height=300))
                
                title = "ØªØ­Ù„ÛŒÙ„ Ø¯ÛŒØªØ§"
                if not use_persian:
                    title = translations.get(title, title)
                generate_pdf(title, elements, buffer)
                
                # ğŸ‘ˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø§ getvalue() Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†
                pdf_data = buffer.getvalue()
                st.download_button(
                    label="Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF",
                    data=pdf_data,
                    file_name="tab10.pdf",
                    mime="application/pdf"
                )
                
                # Ú†Ú© ÙÙˆÙ†Øª
                if not available_fonts:
                    st.warning("âš ï¸ ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. PDF Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯.")
    else:
        st.info("âš ï¸ Ù„Ø·ÙØ§Ù‹ Ù…ØªØºÛŒØ± ÙˆØ§Ø¨Ø³ØªÙ‡ Ùˆ Ø­Ø¯Ø§Ù‚Ù„ ÛŒÚ© Ù…ØªØºÛŒØ± Ù…Ø³ØªÙ‚Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯ ØªØ§ ØªØ­Ù„ÛŒÙ„ Ø´Ø±ÙˆØ¹ Ø´ÙˆØ¯.")

# ----------- Tab11: ØªØ´Ø®ÛŒØµ Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒâ€ŒÙ‡Ø§ -----------
with tab11:
    st.subheader("ğŸš¨ ØªØ´Ø®ÛŒØµ Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒâ€ŒÙ‡Ø§ Ùˆ Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§")

    anomaly_col = st.selectbox("ğŸ”Œ Ø§Ù†ØªØ®Ø§Ø¨ ØªØ¬Ù‡ÛŒØ² Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒ:", columns, key="anomaly_select")
    
    if anomaly_col:
        df_anomaly = filtered_df[["ØªØ§Ø±ÛŒØ®", "ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ", anomaly_col]].dropna().copy()

        if len(df_anomaly) < 2:
            st.warning(f"âš ï¸ Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒ Ø¯Ø± {anomaly_col} ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ (Ø­Ø¯Ø§Ù‚Ù„ 2 Ø±Ú©ÙˆØ±Ø¯ Ù„Ø§Ø²Ù… Ø§Ø³Øª).")
        else:
            X = df_anomaly[[anomaly_col]].values
            iso_forest = IsolationForest(contamination=0.1, random_state=42)
            df_anomaly["is_anomaly"] = iso_forest.fit_predict(X)
            df_anomaly["is_anomaly"] = df_anomaly["is_anomaly"] == -1

            Q1 = df_anomaly[anomaly_col].quantile(0.25)
            Q3 = df_anomaly[anomaly_col].quantile(0.75)
            IQR = Q3 - Q1
            LCL = Q1 - 1.5 * IQR
            UCL = Q3 + 1.5 * IQR

            fig_anomaly = go.Figure()
            normal_data = df_anomaly[~df_anomaly["is_anomaly"]]
            fig_anomaly.add_trace(go.Scatter(
                x=normal_data["ØªØ§Ø±ÛŒØ®"],
                y=normal_data[anomaly_col],
                mode="markers",
                name="Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø±Ù…Ø§Ù„",
                marker=dict(color="blue", size=8)
            ))
            anomaly_data = df_anomaly[df_anomaly["is_anomaly"]]
            if not anomaly_data.empty:
                fig_anomaly.add_trace(go.Scatter(
                    x=anomaly_data["ØªØ§Ø±ÛŒØ®"],
                    y=anomaly_data[anomaly_col],
                    mode="markers",
                    name="Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒâ€ŒÙ‡Ø§",
                    marker=dict(color="red", size=12, symbol="x")
                ))

            fig_anomaly.add_hline(
                y=UCL, line_dash="dash", line_color="red",
                annotation_text=f"UCL = {UCL:.2f}", annotation_position="top right"
            )
            fig_anomaly.add_hline(
                y=LCL, line_dash="dash", line_color="green",
                annotation_text=f"LCL = {LCL:.2f}", annotation_position="bottom right"
            )

            fig_anomaly.update_layout(
                title=f"ğŸ“Š ØªØ´Ø®ÛŒØµ Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒâ€ŒÙ‡Ø§ Ø¯Ø± Ù…ØµØ±Ù {anomaly_col}",
                xaxis_title="ØªØ§Ø±ÛŒØ®",
                yaxis_title="Ù…ØµØ±Ù (MWh)",
                template="plotly_white",
                height=500
            )
            st.plotly_chart(fig_anomaly, use_container_width=True)

            if not anomaly_data.empty:
                st.warning(f"âš ï¸ {len(anomaly_data)} Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒ Ø¯Ø± Ù…ØµØ±Ù {anomaly_col} Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯!")
                st.markdown("ğŸ“‹ **Ø¬Ø¯ÙˆÙ„ Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒâ€ŒÙ‡Ø§**")
                anomaly_table = anomaly_data[["ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ", anomaly_col]].rename(
                    columns={anomaly_col: "Ù…ØµØ±Ù (MWh)", "ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ": "ØªØ§Ø±ÛŒØ®"}
                )
                anomaly_table["Ù…ØµØ±Ù (MWh)"] = anomaly_table["Ù…ØµØ±Ù (MWh)"].round(2)
                st.dataframe(anomaly_table, use_container_width=True)

                st.markdown("### ğŸ” ØªØ­Ù„ÛŒÙ„ Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒâ€ŒÙ‡Ø§")
                for idx, row in anomaly_data.iterrows():
                    date_sh = row["ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ"]
                    value = row[anomaly_col]
                    reason = "Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯ Ø¨Ø§Ù„Ø§" if value > UCL else "Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯ Ù¾Ø§ÛŒÛŒÙ†"
                    st.write(f"- ØªØ§Ø±ÛŒØ®: {date_sh} | Ù…ØµØ±Ù: {value:.2f} MWh | Ø¯Ù„ÛŒÙ„: {reason}")
            else:
                st.success(f"âœ… Ù‡ÛŒÚ† Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒ Ø¯Ø± Ù…ØµØ±Ù {anomaly_col} Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ø´Ø¯.")

            # Ø®Ø±ÙˆØ¬ÛŒ PDF Ø¨Ø±Ø§ÛŒ Tab11
            if st.button("â¬‡ï¸ Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF Tab11"):
                buffer = io.BytesIO()
                elements = []
                
                # ØªÙˆÙ„ÛŒØ¯ ØªØµÙˆÛŒØ± Ø¨Ø§ Ú©ÛŒÙÛŒØª Ø¨Ù‡ØªØ± (Ù†ÛŒØ§Ø² Ø¨Ù‡ kaleido: pip install kaleido)
                img_buf = io.BytesIO()
                fig_anomaly.write_image(img_buf, format='png', width=800, height=500, scale=2)
                img_buf.seek(0)
                elements.append(Image(img_buf, width=500, height=300))
                
                if not anomaly_data.empty:
                    data = [anomaly_table.columns.tolist()] + anomaly_table.values.tolist()
                    
                    # ØªØ±Ø¬Ù…Ù‡ Ù‡Ø¯Ø±Ù‡Ø§ Ø§Ú¯Ø± Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
                    translations_local = {
                        "ØªØ§Ø±ÛŒØ®": "Date",
                        "Ù…ØµØ±Ù (MWh)": "Consumption (MWh)"
                    }
                    use_persian = available_fonts and font_name != "Helvetica"
                    if not use_persian and data and isinstance(data[0], list) and len(data[0]) >= 2:
                        data[0][0] = translations_local.get(data[0][0], data[0][0])
                        data[0][1] = translations_local.get(data[0][1], data[0][1])
                    
                    # Reshape Ù…ØªÙ†â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ RTL Ø§Ú¯Ø± ÙØ§Ø±Ø³ÛŒ (ÙÙ‚Ø· Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§)
                    if use_persian:
                        try:
                            import arabic_reshaper
                            from bidi.algorithm import get_display
                            for row in data:
                                for i, cell in enumerate(row):
                                    if isinstance(cell, str):
                                        row[i] = get_display(arabic_reshaper.reshape(cell))
                        except ImportError:
                            st.warning("Ø¨Ø±Ø§ÛŒ RTL Ø¯Ø± Ø¬Ø¯ÙˆÙ„ØŒ arabic-reshaper Ùˆ python-bidi Ø±Ùˆ Ù†ØµØ¨ Ú©Ù†.")
                    
                    table = Table(data)
                    table.setStyle(TableStyle([
                        ('BACKGROUND', (0,0), (-1,0), colors.lightgrey),  # Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ø¹Ù†ÙˆØ§Ù†
                        ('TEXTCOLOR', (0,0), (-1,0), colors.black),       # Ù…ØªÙ† Ø¹Ù†ÙˆØ§Ù†
                        ('GRID', (0,0), (-1,-1), 0.5, colors.lightgrey),  # ğŸ‘ˆ grid Ú©Ù…â€ŒØ±Ù†Ú¯ (Ù†Ù‡ Ù…Ø´Ú©ÛŒ)
                        ('ALIGN', (0,0), (-1,-1), 'CENTER')
                    ]))
                    elements.append(table)
                
                title = "ØªØ´Ø®ÛŒØµ Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒâ€ŒÙ‡Ø§"
                if not use_persian:
                    title = translations.get(title, title)
                generate_pdf(title, elements, buffer)
                
                # ğŸ‘ˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø§ getvalue() Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†
                pdf_data = buffer.getvalue()
                st.download_button(
                    label="Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF",
                    data=pdf_data,
                    file_name="tab11.pdf",
                    mime="application/pdf"
                )
                
                # Ú†Ú© ÙÙˆÙ†Øª
                if not available_fonts:
                    st.warning("âš ï¸ ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. PDF Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯.")

# ----------- Tab12: Ú¯Ø²Ø§Ø±Ø´ Ø²ÛŒØ³Øªâ€ŒÙ…Ø­ÛŒØ·ÛŒ (Ø¯Ø§Ø±Ù‡ØŒ ØªØºÛŒÛŒØ± ÙÙˆÙ†Øª) -----------
with tab12:
    st.subheader("ğŸŒ Ú¯Ø²Ø§Ø±Ø´ Ø²ÛŒØ³Øªâ€ŒÙ…Ø­ÛŒØ·ÛŒ Ùˆ Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ")

    env_cols = st.multiselect("ğŸ”Œ Ø§Ù†ØªØ®Ø§Ø¨ ØªØ¬Ù‡ÛŒØ²Ø§Øª Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø²ÛŒØ³Øªâ€ŒÙ…Ø­ÛŒØ·ÛŒ:", 
                              columns, 
                              default=columns[:3] if columns else [],
                              key="env_multiselect")

    if env_cols:
        use_persian = available_fonts and font_name != "Helvetica"
        lang_mode = "fa" if use_persian else "en"

        st.markdown("### âš™ï¸ ØªÙ†Ø¸ÛŒÙ…Ø§Øª")
        co2_factor = st.number_input(
            "ÙØ§Ú©ØªÙˆØ± Ø§Ù†ØªØ´Ø§Ø± CO2 (kg CO2/kWh):",
            min_value=0.0,
            value=0.5,
            step=0.01,
            key="co2_factor"
        )
        reduction_target = st.number_input(
            "Ù‡Ø¯Ù Ú©Ø§Ù‡Ø´ Ø§Ù†ØªØ´Ø§Ø± CO2 (%):",
            min_value=0.0,
            max_value=100.0,
            value=10.0,
            step=1.0,
            key="reduction_target"
        )

        df_env = filtered_df[["ØªØ§Ø±ÛŒØ®", "ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ"] + env_cols].copy()
        for col in env_cols:
            df_env[f"CO2_{col}"] = df_env[col] * 1000 * co2_factor

        co2_columns = [f"CO2_{col}" for col in env_cols]
        df_env["CO2_Total"] = df_env[co2_columns].sum(axis=1)

        fig_co2 = px.line(
            df_env,
            x="ØªØ§Ø±ÛŒØ®",
            y="CO2_Total",
            title="ğŸ“ˆ Ø±ÙˆÙ†Ø¯ Ø§Ù†ØªØ´Ø§Ø± CO2 Ú©Ù„" if lang_mode=="fa" else "ğŸ“ˆ Total CO2 Emissions Trend",
            template="plotly_white",
            markers=True
        )
        fig_co2.update_layout(
            xaxis_title="ØªØ§Ø±ÛŒØ®" if lang_mode=="fa" else "Date",
            yaxis_title="Ø§Ù†ØªØ´Ø§Ø± CO2 (kg)" if lang_mode=="fa" else "CO2 Emissions (kg)",
            height=500
        )
        st.plotly_chart(fig_co2, use_container_width=True)

        co2_totals = df_env[co2_columns].sum().reset_index()
        co2_totals.columns = ["ØªØ¬Ù‡ÛŒØ²" if lang_mode=="fa" else "Equipment", "CO2 (kg)"]
        co2_totals["ØªØ¬Ù‡ÛŒØ²" if lang_mode=="fa" else "Equipment"] = co2_totals[
            "ØªØ¬Ù‡ÛŒØ²" if lang_mode=="fa" else "Equipment"
        ].str.replace("CO2_", "")
        fig_pie = px.pie(
            co2_totals,
            names="ØªØ¬Ù‡ÛŒØ²" if lang_mode=="fa" else "Equipment",
            values="CO2 (kg)",
            title="ğŸ¥§ ØªÙˆØ²ÛŒØ¹ Ø§Ù†ØªØ´Ø§Ø± CO2 Ø¨ÛŒÙ† ØªØ¬Ù‡ÛŒØ²Ø§Øª" if lang_mode=="fa" else "ğŸ¥§ CO2 Emission Distribution by Equipment",
            template="plotly_white"
        )
        st.plotly_chart(fig_pie, use_container_width=True)

        total_co2 = df_env["CO2_Total"].sum()
        target_co2 = total_co2 * (1 - reduction_target / 100)
        st.markdown("### ğŸ” ØªØ­Ù„ÛŒÙ„ Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ" if lang_mode=="fa" else "### ğŸ” Sustainability Analysis")
        if lang_mode == "fa":
            st.write(f"- **Ú©Ù„ Ø§Ù†ØªØ´Ø§Ø± CO2**: {total_co2:,.2f} kg")
            st.write(f"- **Ù‡Ø¯Ù Ú©Ø§Ù‡Ø´ CO2**: {target_co2:,.2f} kg (Ú©Ø§Ù‡Ø´ {reduction_target}%)")
        else:
            st.write(f"- **Total CO2 Emissions**: {total_co2:,.2f} kg")
            st.write(f"- **Target CO2 Emissions**: {target_co2:,.2f} kg (Reduction {reduction_target}%)")

        if total_co2 > target_co2:
            if lang_mode == "fa":
                st.warning(f"âš ï¸ Ø§Ù†ØªØ´Ø§Ø± ÙØ¹Ù„ÛŒ {total_co2 - target_co2:,.2f} kg Ø¨ÛŒØ´ØªØ± Ø§Ø² Ù‡Ø¯Ù Ø§Ø³Øª.")
            else:
                st.warning(f"âš ï¸ Current emissions exceed the target by {total_co2 - target_co2:,.2f} kg.")
        else:
            if lang_mode == "fa":
                st.success("âœ… Ø§Ù†ØªØ´Ø§Ø± ÙØ¹Ù„ÛŒ Ø¯Ø± Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ù‡Ø¯Ù Ú©Ø§Ù‡Ø´ Ø§Ø³Øª!")
            else:
                st.success("âœ… Current emissions are within the reduction target!")

        st.markdown("### ğŸ“ ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ PDF" if lang_mode=="fa" else "### ğŸ“ Generate PDF Report")
        buffer = io.BytesIO()
        elements = []

        elements.append(Paragraph("Ú¯Ø²Ø§Ø±Ø´ Ø²ÛŒØ³Øªâ€ŒÙ…Ø­ÛŒØ·ÛŒ Ùˆ Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ" if lang_mode=="fa" else "Environmental & Sustainability Report", ParagraphStyle('Title', alignment=1 if lang_mode=="fa" else 0)))
        elements.append(Spacer(1, 12))

        if lang_mode == "fa":
            summary_data = [
                ["Ù…Ø¹ÛŒØ§Ø±", "Ù…Ù‚Ø¯Ø§Ø±"],
                ["Ú©Ù„ Ø§Ù†ØªØ´Ø§Ø± CO2 (kg)", f"{total_co2:,.2f}"],
                ["Ù‡Ø¯Ù Ú©Ø§Ù‡Ø´ CO2 (kg)", f"{target_co2:,.2f}"],
                ["ÙØ§Ú©ØªÙˆØ± Ø§Ù†ØªØ´Ø§Ø± (kg CO2/kWh)", f"{co2_factor:.2f}"],
                ["Ù‡Ø¯Ù Ú©Ø§Ù‡Ø´ (%)", f"{reduction_target:.1f}"]
            ]
        else:
            summary_data = [
                ["Metric", "Value"],
                ["Total CO2 Emissions (kg)", f"{total_co2:,.2f}"],
                ["Target CO2 (kg)", f"{target_co2:,.2f}"],
                ["Emission Factor (kg CO2/kWh)", f"{co2_factor:.2f}"],
                ["Reduction Target (%)", f"{reduction_target:.1f}"]
            ]

        table_summary = Table(summary_data)
        table_summary.setStyle(TableStyle([
            ("BACKGROUND", (0, 0), (-1, 0), colors.lightgrey),
            ("TEXTCOLOR", (0, 0), (-1, -1), colors.black),
            ("GRID", (0, 0), (-1, -1), 1, colors.black),
            ("ALIGN", (0, 0), (-1, -1), "CENTER"),
        ]))
        elements.append(Paragraph("Ø®Ù„Ø§ØµÙ‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø²ÛŒØ³Øªâ€ŒÙ…Ø­ÛŒØ·ÛŒ" if lang_mode=="fa" else "Environmental Summary", ParagraphStyle('Normal', alignment=1 if lang_mode=="fa" else 0)))
        elements.append(Spacer(1, 12))
        elements.append(table_summary)

        if lang_mode == "fa":
            equipment_data = [["ØªØ¬Ù‡ÛŒØ²", "Ø§Ù†ØªØ´Ø§Ø± CO2 (kg)"]] + co2_totals.values.tolist()
        else:
            equipment_data = [["Equipment", "CO2 (kg)"]] + co2_totals.values.tolist()

        table_equipment = Table(equipment_data)
        table_equipment.setStyle(TableStyle([
            ("BACKGROUND", (0, 0), (-1, 0), colors.lightgrey),
            ("TEXTCOLOR", (0, 0), (-1, -1), colors.black),
            ("GRID", (0, 0), (-1, -1), 1, colors.black),
            ("ALIGN", (0, 0), (-1, -1), "CENTER"),
        ]))
        elements.append(Spacer(1, 12))
        elements.append(Paragraph("ØªÙˆØ²ÛŒØ¹ Ø§Ù†ØªØ´Ø§Ø± CO2 Ø¨ÛŒÙ† ØªØ¬Ù‡ÛŒØ²Ø§Øª" if lang_mode=="fa" else "CO2 Distribution by Equipment", ParagraphStyle('Normal', alignment=1 if lang_mode=="fa" else 0)))
        elements.append(Spacer(1, 12))
        elements.append(table_equipment)

        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ Ø¨Ù‡ PDF
        img_buf_co2 = io.BytesIO()
        import io

# Ø§ÛŒØ¬Ø§Ø¯ Ø¨Ø§ÛŒØªâ€ŒØ§Ø³ØªØ±ÛŒÙ… Ø§Ø² ØªØµÙˆÛŒØ± Ø¨Ø¯ÙˆÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ Kaleido
        img_buf_co2 = io.BytesIO()
        img_bytes = fig_co2.to_image(format="png", width=800, height=500, scale=2)
        img_buf_co2.write(img_bytes)
        img_buf_co2.seek(0)
        img_buf_co2.seek(0)
        elements.append(Image(img_buf_co2, width=500, height=300))

        img_buf_pie = io.BytesIO()
        fig_pie.write_image(img_buf_pie, format='png', width=800, height=500, scale=2)
        img_buf_pie.seek(0)
        elements.append(Image(img_buf_pie, width=500, height=300))

        title = "Ú¯Ø²Ø§Ø±Ø´ Ø²ÛŒØ³Øªâ€ŒÙ…Ø­ÛŒØ·ÛŒ"
        if not use_persian:
            title = translations.get(title, title)
        generate_pdf(title, elements, buffer)

        # ğŸ‘ˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø§ getvalue() Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†
        pdf_data = buffer.getvalue()
        st.download_button(
            label="â¬‡ï¸ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú¯Ø²Ø§Ø±Ø´ Ø²ÛŒØ³Øªâ€ŒÙ…Ø­ÛŒØ·ÛŒ (PDF)" if lang_mode=="fa" else "â¬‡ï¸ Download Environmental Report (PDF)",
            data=pdf_data,
            file_name="Ú¯Ø²Ø§Ø±Ø´_Ø²ÛŒØ³Øª_Ù…Ø­ÛŒØ·ÛŒ.pdf" if lang_mode=="fa" else "Environmental_Report.pdf",
            mime="application/pdf"
        )
        
        # Ú†Ú© ÙÙˆÙ†Øª
        if not available_fonts:
            st.warning("âš ï¸ ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. PDF Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯.")

# ----------- Tab13: Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ù‡Ø§ -----------
with tab13:
    st.subheader("ğŸ­ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ù‡Ø§ÛŒ ØµÙ†Ø¹ØªÛŒ")
    
    uploaded_std = st.file_uploader("ğŸ“‚ Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ (CSV)", type=["csv"])
    if uploaded_std:
        standards_df = pd.read_csv(uploaded_std)
        st.dataframe(standards_df)
        
        if 'ØªÙˆÙ„ÛŒØ¯ (ØªÙ†)' not in filtered_df.columns:
            production = st.number_input("ğŸ“ Ù…Ù‚Ø¯Ø§Ø± ØªÙˆÙ„ÛŒØ¯ Ú©Ù„ (ØªÙ†):", value=1000.0)
        else:
            production = filtered_df['ØªÙˆÙ„ÛŒØ¯ (ØªÙ†)'].sum()
        
        selected_col = st.selectbox("ğŸ”Œ Ø§Ù†ØªØ®Ø§Ø¨ ØªØ¬Ù‡ÛŒØ²:", columns)
        
        if selected_col and not standards_df.empty:
            actual_consumption_per_ton = filtered_df[selected_col].sum() / production
            std_value = standards_df[standards_df['ØªØ¬Ù‡ÛŒØ²'] == selected_col]['Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ kWh/ØªÙ†'].iloc[0] if selected_col in standards_df['ØªØ¬Ù‡ÛŒØ²'].values else 0.5
            
            deviation = ((actual_consumption_per_ton - std_value) / std_value) * 100
            
            fig_gauge = go.Figure(go.Indicator(
                mode="gauge+number+delta",
                value=deviation,
                domain={'x': [0, 1], 'y': [0, 1]},
                title={'text': "Ø§Ù†Ø­Ø±Ø§Ù Ø§Ø² Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ (%)"},
                delta={'reference': 0},
                gauge={
                    'axis': {'range': [-100, 100]},
                    'bar': {'color': "darkblue"},
                    'steps': [
                        {'range': [-100, -20], 'color': "red"},
                        {'range': [-20, 20], 'color': "yellow"},
                        {'range': [20, 100], 'color': "green"}
                    ],
                    'threshold': {
                        'line': {'color': "red", 'width': 4},
                        'thickness': 0.75,
                        'value': 20
                    }
                }
            ))
            st.plotly_chart(fig_gauge, use_container_width=True)
            
            st.metric("Ù…ØµØ±Ù ÙˆØ§Ù‚Ø¹ÛŒ (kWh/ØªÙ†)", f"{actual_consumption_per_ton:.2f}")
            st.metric("Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ (kWh/ØªÙ†)", f"{std_value:.2f}")
            st.info(f"Ø§Ù†Ø­Ø±Ø§Ù: {deviation:.1f}% {'(Ø¨Ø§Ù„Ø§ØªØ± Ø§Ø² Ø­Ø¯ Ù…Ø¬Ø§Ø²)' if deviation > 20 else '(Ø¯Ø± Ù…Ø­Ø¯ÙˆØ¯Ù‡)'}")

            # Ø®Ø±ÙˆØ¬ÛŒ PDF Ø¨Ø±Ø§ÛŒ Tab13
            if st.button("â¬‡ï¸ Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF Tab13"):
                buffer = io.BytesIO()
                elements = []
                
                # ØªÙˆÙ„ÛŒØ¯ ØªØµÙˆÛŒØ± Ø¨Ø§ Ú©ÛŒÙÛŒØª Ø¨Ù‡ØªØ± (Ù†ÛŒØ§Ø² Ø¨Ù‡ kaleido: pip install kaleido)
                img_buf = io.BytesIO()
                fig_gauge.write_image(img_buf, format='png', width=800, height=400, scale=2)
                img_buf.seek(0)
                elements.append(Image(img_buf, width=500, height=300))
                
                title = "Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ù‡Ø§ÛŒ ØµÙ†Ø¹ØªÛŒ"
                if not use_persian:
                    title = translations.get(title, title)
                generate_pdf(title, elements, buffer)
                
                # ğŸ‘ˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø§ getvalue() Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†
                pdf_data = buffer.getvalue()
                st.download_button(
                    label="Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF",
                    data=pdf_data,
                    file_name="tab13.pdf",
                    mime="application/pdf"
                )
                
                # Ú†Ú© ÙÙˆÙ†Øª
                if not available_fonts:
                    st.warning("âš ï¸ ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. PDF Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯.")
    else:
        st.info("ğŸ“Œ Ù†Ù…ÙˆÙ†Ù‡ CSV: Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ 'ØªØ¬Ù‡ÛŒØ²' Ùˆ 'Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ kWh/ØªÙ†'")

# ----------- Tab14: ØªØ­Ù„ÛŒÙ„ Ù‡Ø²ÛŒÙ†Ù‡ -----------
with tab14:
    st.subheader("ğŸ’° ØªØ­Ù„ÛŒÙ„ Ù‡Ø²ÛŒÙ†Ù‡ Ùˆ Ø¨ÙˆØ¯Ø¬Ù‡")
    
    rate_peak = st.number_input("ğŸ’¸ Ù†Ø±Ø® Ø§ÙˆØ¬ (ØªÙˆÙ…Ø§Ù†/kWh):", value=1000.0)
    rate_offpeak = st.number_input("ğŸ’¸ Ù†Ø±Ø® Ø®Ø§Ø±Ø¬ Ø§ÙˆØ¬ (ØªÙˆÙ…Ø§Ù†/kWh):", value=500.0)
    peak_hours = st.slider("â° Ø³Ø§Ø¹Ø§Øª Ø§ÙˆØ¬ Ø±ÙˆØ²Ø§Ù†Ù‡:", 0, 24, 8)
    
    if 'Ø³Ø§Ø¹Øª' in filtered_df.columns:
        peak_consumption = filtered_df[filtered_df['Ø³Ø§Ø¹Øª'] >= peak_hours][columns].sum().sum()
        offpeak_consumption = filtered_df[filtered_df['Ø³Ø§Ø¹Øª'] < peak_hours][columns].sum().sum()
    else:
        total_consumption = filtered_df[columns].sum().sum()
        peak_consumption = total_consumption * (peak_hours / 24)
        offpeak_consumption = total_consumption - peak_consumption
    
    peak_cost = peak_consumption * rate_peak
    offpeak_cost = offpeak_consumption * rate_offpeak
    total_cost = peak_cost + offpeak_cost
    
    cost_df = pd.DataFrame({
        'Ø¯ÙˆØ±Ù‡': ['Ø§ÙˆØ¬', 'Ø®Ø§Ø±Ø¬ Ø§ÙˆØ¬', 'Ú©Ù„'],
        'Ù…ØµØ±Ù (kWh)': [peak_consumption, offpeak_consumption, total_consumption],
        'Ù‡Ø²ÛŒÙ†Ù‡ (ØªÙˆÙ…Ø§Ù†)': [peak_cost, offpeak_cost, total_cost]
    })
    st.dataframe(cost_df.style.format({'Ù‡Ø²ÛŒÙ†Ù‡ (ØªÙˆÙ…Ø§Ù†)': '{:,.0f}'}))
    
    fig_sankey = go.Figure(data=[go.Sankey(
        node=dict(
            label=["Ù…ØµØ±Ù Ø§ÙˆØ¬", "Ù…ØµØ±Ù Ø®Ø§Ø±Ø¬ Ø§ÙˆØ¬", "Ú©Ù„ Ù‡Ø²ÛŒÙ†Ù‡"],
            color="blue"
        ),
        link=dict(
            source=[0, 1, 0, 1],
            target=[2, 2, 2, 2],
            value=[peak_cost, offpeak_cost, peak_cost, offpeak_cost]
        )
    )])
    fig_sankey.update_layout(title="Ø¬Ø±ÛŒØ§Ù† Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§")
    st.plotly_chart(fig_sankey, use_container_width=True)
    
    budget = st.number_input("ğŸ¯ Ø¨ÙˆØ¯Ø¬Ù‡ Ù…Ø§Ù‡Ø§Ù†Ù‡ (ØªÙˆÙ…Ø§Ù†):", value=total_cost * 1.2)
    st.metric("Ù‡Ø²ÛŒÙ†Ù‡ Ú©Ù„", f"{total_cost:,.0f} ØªÙˆÙ…Ø§Ù†", delta=f"{total_cost - budget:.0f}")

    # Ø®Ø±ÙˆØ¬ÛŒ PDF Ø¨Ø±Ø§ÛŒ Tab14
    if st.button("â¬‡ï¸ Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF Tab14"):
        buffer = io.BytesIO()
        elements = []
        
        data = [cost_df.columns.tolist()] + cost_df.values.tolist()
        
        # ØªØ±Ø¬Ù…Ù‡ Ù‡Ø¯Ø±Ù‡Ø§ Ø§Ú¯Ø± Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
        translations_local = {
            "Ø¯ÙˆØ±Ù‡": "Period",
            "Ù…ØµØ±Ù (kWh)": "Consumption (kWh)",
            "Ù‡Ø²ÛŒÙ†Ù‡ (ØªÙˆÙ…Ø§Ù†)": "Cost (Toman)"
        }
        use_persian = available_fonts and font_name != "Helvetica"
        if not use_persian and data and isinstance(data[0], list) and len(data[0]) >= 3:
            data[0][0] = translations_local.get(data[0][0], data[0][0])
            data[0][1] = translations_local.get(data[0][1], data[0][1])
            data[0][2] = translations_local.get(data[0][2], data[0][2])
        
        # Reshape Ù…ØªÙ†â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ RTL Ø§Ú¯Ø± ÙØ§Ø±Ø³ÛŒ (ÙÙ‚Ø· Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§)
        if use_persian:
            try:
                import arabic_reshaper
                from bidi.algorithm import get_display
                for row in data:
                    for i, cell in enumerate(row):
                        if isinstance(cell, str):
                            row[i] = get_display(arabic_reshaper.reshape(cell))
            except ImportError:
                st.warning("Ø¨Ø±Ø§ÛŒ RTL Ø¯Ø± Ø¬Ø¯ÙˆÙ„ØŒ arabic-reshaper Ùˆ python-bidi Ø±Ùˆ Ù†ØµØ¨ Ú©Ù†.")
        
        table = Table(data)
        table.setStyle(TableStyle([
            ('BACKGROUND', (0,0), (-1,0), colors.lightgrey),  # Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ø¹Ù†ÙˆØ§Ù†
            ('TEXTCOLOR', (0,0), (-1,0), colors.black),       # Ù…ØªÙ† Ø¹Ù†ÙˆØ§Ù†
            ('GRID', (0,0), (-1,-1), 0.5, colors.lightgrey),  # ğŸ‘ˆ grid Ú©Ù…â€ŒØ±Ù†Ú¯ (Ù†Ù‡ Ù…Ø´Ú©ÛŒ)
            ('ALIGN', (0,0), (-1,-1), 'CENTER')
        ]))
        elements.append(table)
        
        # ØªÙˆÙ„ÛŒØ¯ ØªØµÙˆÛŒØ± Ø¨Ø§ Ú©ÛŒÙÛŒØª Ø¨Ù‡ØªØ± (Ù†ÛŒØ§Ø² Ø¨Ù‡ kaleido: pip install kaleido)
        img_buf = io.BytesIO()
        fig_sankey.write_image(img_buf, format='png', width=800, height=400, scale=2)
        img_buf.seek(0)
        elements.append(Image(img_buf, width=500, height=300))
        
        title = "ØªØ­Ù„ÛŒÙ„ Ù‡Ø²ÛŒÙ†Ù‡ Ùˆ Ø¨ÙˆØ¯Ø¬Ù‡"
        if not use_persian:
            title = translations.get(title, title)
        generate_pdf(title, elements, buffer)
        
        # ğŸ‘ˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø§ getvalue() Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†
        pdf_data = buffer.getvalue()
        st.download_button(
            label="Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF",
            data=pdf_data,
            file_name="tab14.pdf",
            mime="application/pdf"
        )
        
        # Ú†Ú© ÙÙˆÙ†Øª
        if not available_fonts:
            st.warning("âš ï¸ ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. PDF Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯.")

# ----------- Tab15: Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ ØªØ¹Ø§Ù…Ù„ÛŒ -----------
with tab15:
    st.subheader("ğŸ“± Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ ØªØ¹Ø§Ù…Ù„ÛŒ Ø²Ù†Ø¯Ù‡")
    
    view_selector = st.selectbox("ğŸ”„ Ø§Ù†ØªØ®Ø§Ø¨ ÙˆÛŒÙˆ:", ["KPI Ø®Ù„Ø§ØµÙ‡", "Ø±ÙˆÙ†Ø¯ Ø³Ø±ÛŒØ¹",])
    
    selected_cols = st.multiselect("ğŸ”Œ ØªØ¬Ù‡ÛŒØ²Ø§Øª:", columns, default=columns[:3])
    
    if selected_cols:
        if view_selector == "KPI Ø®Ù„Ø§ØµÙ‡":
            col1, col2, col3 = st.columns(3)
            for i, col in enumerate(selected_cols):
                c = [col1, col2, col3][i % 3]
                with c:
                    total = filtered_df[col].sum()
                    st.metric(f"{col}", f"{total:,.0f} MWh")
        
        elif view_selector == "Ø±ÙˆÙ†Ø¯ Ø³Ø±ÛŒØ¹":
            df_quick = filtered_df.groupby(filtered_df["ØªØ§Ø±ÛŒØ®"].dt.to_period("M"))[selected_cols].sum().reset_index()
            df_quick["Ù…Ø§Ù‡"] = df_quick["ØªØ§Ø±ÛŒØ®"].dt.strftime('%Y/%m')
            fig_quick = px.line(df_quick, x="Ù…Ø§Ù‡", y=selected_cols, title="Ø±ÙˆÙ†Ø¯ Ù…Ø§Ù‡Ø§Ù†Ù‡")
            st.plotly_chart(fig_quick, use_container_width=True)
    
    st.info("ğŸ”„ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ù‡Ø± Û³Û° Ø«Ø§Ù†ÛŒÙ‡ Ø±ÙØ±Ø´ Ù…ÛŒâ€ŒØ´ÙˆØ¯ (Ø¯Ø± Ù…Ø­ÛŒØ· ÙˆØ§Ù‚Ø¹ÛŒ).")

    # Ø®Ø±ÙˆØ¬ÛŒ PDF Ø¨Ø±Ø§ÛŒ Tab15
    if st.button("â¬‡ï¸ Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF Tab15"):
        buffer = io.BytesIO()
        elements = []
        
        if view_selector == "Ø±ÙˆÙ†Ø¯ Ø³Ø±ÛŒØ¹":
            # ØªÙˆÙ„ÛŒØ¯ ØªØµÙˆÛŒØ± Ø¨Ø§ Ú©ÛŒÙÛŒØª Ø¨Ù‡ØªØ± (Ù†ÛŒØ§Ø² Ø¨Ù‡ kaleido: pip install kaleido)
            img_buf = io.BytesIO()
            fig_quick.write_image(img_buf, format='png', width=800, height=400, scale=2)
            img_buf.seek(0)
            elements.append(Image(img_buf, width=500, height=300))
        
        title = "Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ ØªØ¹Ø§Ù…Ù„ÛŒ Ø²Ù†Ø¯Ù‡"
        if not use_persian:
            title = translations.get(title, title)
        generate_pdf(title, elements, buffer)
        
        # ğŸ‘ˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø§ getvalue() Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†
        pdf_data = buffer.getvalue()
        st.download_button(
            label="Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF",
            data=pdf_data,
            file_name="tab15.pdf",
            mime="application/pdf"
        )
        
        # Ú†Ú© ÙÙˆÙ†Øª
        if not available_fonts:
            st.warning("âš ï¸ ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. PDF Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯.")

# ----------- Tab16: Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ÛŒ Ø³ÙØ§Ø±Ø´ÛŒ (Ø¯Ø§Ø±Ù‡ØŒ ØªØºÛŒÛŒØ± ÙÙˆÙ†Øª) -----------
with tab16:
    st.subheader("ğŸ“± Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ÛŒ Ø³ÙØ§Ø±Ø´ÛŒ Ùˆ ÙˆØ§ØªØ³Ø§Ù¾")
    
    uploaded_font = st.file_uploader("ğŸ–‹ Ø¢Ù¾Ù„ÙˆØ¯ ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ (TTF, Ù…Ø«Ù„ BNazanin.ttf)", type=["ttf"])
    font_path_tab16 = None
    if uploaded_font:
        with open("temp_font_tab16.ttf", "wb") as f:
            f.write(uploaded_font.getvalue())
        font_path_tab16 = "temp_font_tab16.ttf"
    else:
        font_path_tab16 = r"D:\BNazanin.ttf"
        if not os.path.exists(font_path_tab16):
            st.warning("âš ï¸ ÙÙˆÙ†Øª B Nazanin Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
    
    include_kpi = st.checkbox("Ø´Ø§Ù…Ù„ KPI")
    include_trend = st.checkbox("Ø´Ø§Ù…Ù„ Ø±ÙˆÙ†Ø¯")
    selected_cols_report = st.multiselect("ØªØ¬Ù‡ÛŒØ²Ø§Øª:", columns, default=columns[:2])
    
    st.markdown("### ğŸ“… Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ")
    min_date, max_date = filtered_df["ØªØ§Ø±ÛŒØ®"].min(), filtered_df["ØªØ§Ø±ÛŒØ®"].max()
    start_date, end_date = st.date_input("Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ", [min_date, max_date], key="report_date_range")
    st.markdown(f"**ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ Ø´Ø±ÙˆØ¹:** {JalaliDate(start_date).strftime('%Y/%m/%d')}")
    st.markdown(f"**ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ Ù¾Ø§ÛŒØ§Ù†:** {JalaliDate(end_date).strftime('%Y/%m/%d')}")
    
    mask_report = (filtered_df["ØªØ§Ø±ÛŒØ®"] >= pd.to_datetime(start_date)) & (filtered_df["ØªØ§Ø±ÛŒØ®"] <= pd.to_datetime(end_date))
    filtered_report_df = filtered_df.loc[mask_report].copy()
    
    if filtered_report_df.empty:
        st.warning("âš ï¸ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ù‡ Ø§Ù†ØªØ®Ø§Ø¨â€ŒØ´Ø¯Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        st.stop()
    
    granularity = st.selectbox("ğŸ“Š Ø³Ø·Ø­ Ø¬Ø²Ø¦ÛŒØ§Øª Ø®Ø±ÙˆØ¬ÛŒ:", ["Ø±ÙˆØ²Ø§Ù†Ù‡", "Ù…Ø§Ù‡Ø§Ù†Ù‡"], key="granularity")
    
    if st.button("ğŸ“ ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´"):
        if not selected_cols_report:
            st.error("âš ï¸ Ø­Ø¯Ø§Ù‚Ù„ ÛŒÚ© ØªØ¬Ù‡ÛŒØ² Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯!")
            st.stop()
        
        buffer = io.BytesIO()
        elements = []
        
        use_persian = available_fonts and font_name != "Helvetica"
        if font_path_tab16 and os.path.exists(font_path_tab16):
            try:
                pdfmetrics.registerFont(TTFont("BNazanin", font_path_tab16))
                title_style = ParagraphStyle(
                    name='TitleRTL',
                    parent=getSampleStyleSheet()['Title'],
                    fontName="BNazanin",
                    fontSize=18,
                    alignment=1
                )
                normal_style = ParagraphStyle(
                    name='RTLStyle',
                    parent=getSampleStyleSheet()['Normal'],
                    fontName="BNazanin",
                    fontSize=12,
                    leading=14,
                    alignment=1,
                    spaceAfter=12
                )
                st.success("âœ… ÙÙˆÙ†Øª B Nazanin Ø«Ø¨Øª Ø´Ø¯.")
            except Exception as e:
                st.error(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± ÙÙˆÙ†Øª: {e}")
                title_style = getSampleStyleSheet()['Title']
                normal_style = getSampleStyleSheet()['Normal']
        else:
            title_style = getSampleStyleSheet()['Title']
            normal_style = getSampleStyleSheet()['Normal']
        
        title_text = f"Ú¯Ø²Ø§Ø±Ø´ Ø³ÙØ§Ø±Ø´ÛŒ Ù¾Ø§ÛŒØ´ Ø¨Ø±Ù‚ ({JalaliDate(start_date).strftime('%Y/%m/%d')} ØªØ§ {JalaliDate(end_date).strftime('%Y/%m/%d')})"
        elements.append(Paragraph(title_text, title_style))
        elements.append(Spacer(1, 12))
        
        if include_kpi:
            elements.append(Paragraph("Ø¬Ø¯ÙˆÙ„ KPI", normal_style))
            if granularity == "Ø±ÙˆØ²Ø§Ù†Ù‡":
                kpi_summary = filtered_report_df[selected_cols_report].sum()
                kpi_data = [['ØªØ¬Ù‡ÛŒØ²', 'Ù…Ø¬Ù…ÙˆØ¹ Ø¨Ø§Ø²Ù‡']] + [[col, f"{kpi_summary[col]:.2f}"] for col in selected_cols_report]
            else:
                filtered_report_df["Ù…Ø§Ù‡ Ø´Ù…Ø³ÛŒ"] = filtered_report_df["ØªØ§Ø±ÛŒØ®"].map(lambda x: JalaliDate(x).strftime('%Y/%m'))
                kpi_monthly = filtered_report_df.groupby("Ù…Ø§Ù‡ Ø´Ù…Ø³ÛŒ")[selected_cols_report].sum()
                kpi_data = [['ØªØ¬Ù‡ÛŒØ²', 'Ù…Ø¬Ù…ÙˆØ¹ Ø¨Ø§Ø²Ù‡']] + [[col, f"{kpi_monthly[col].sum():.2f}"] for col in selected_cols_report]
            
            # ØªØ±Ø¬Ù…Ù‡ Ù‡Ø¯Ø±Ù‡Ø§ Ø§Ú¯Ø± Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
            translations_local = {
                "ØªØ¬Ù‡ÛŒØ²": "Equipment",
                "Ù…Ø¬Ù…ÙˆØ¹ Ø¨Ø§Ø²Ù‡": "Total Period"
            }
            if not use_persian and kpi_data and isinstance(kpi_data[0], list):
                kpi_data[0][0] = translations_local.get(kpi_data[0][0], kpi_data[0][0])
                kpi_data[0][1] = translations_local.get(kpi_data[0][1], kpi_data[0][1])
            
            # Reshape Ù…ØªÙ†â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ RTL Ø§Ú¯Ø± ÙØ§Ø±Ø³ÛŒ (ÙÙ‚Ø· Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§)
            if use_persian:
                try:
                    import arabic_reshaper
                    from bidi.algorithm import get_display
                    for row in kpi_data:
                        for i, cell in enumerate(row):
                            if isinstance(cell, str):
                                row[i] = get_display(arabic_reshaper.reshape(cell))
                except ImportError:
                    st.warning("Ø¨Ø±Ø§ÛŒ RTL Ø¯Ø± Ø¬Ø¯ÙˆÙ„ØŒ arabic-reshaper Ùˆ python-bidi Ø±Ùˆ Ù†ØµØ¨ Ú©Ù†.")
            
            table = Table(kpi_data)
            table.setStyle(TableStyle([
                ('BACKGROUND', (0,0), (-1,0), colors.lightblue),
                ('TEXTCOLOR', (0,0), (-1,-1), colors.black),
                ('GRID', (0,0), (-1,-1), 1, colors.darkblue),
                ('ALIGN', (0,0), (-1,-1), 'CENTER'),
            ]))
            elements.append(table)
            elements.append(Spacer(1, 12))
        
        if include_trend:
            elements.append(Paragraph(f"Ù†Ù…ÙˆØ¯Ø§Ø± Ø±ÙˆÙ†Ø¯ Ù…ØµØ±Ù ({granularity})", normal_style))
            
            df_trend = filtered_report_df.copy()
            if granularity == "Ø±ÙˆØ²Ø§Ù†Ù‡":
                df_trend["ØªØ§Ø±ÛŒØ® Ù†Ù…Ø§ÛŒØ´"] = df_trend["ØªØ§Ø±ÛŒØ®"].map(lambda x: JalaliDate(x).strftime('%Y/%m/%d'))
                df_trend = df_trend.groupby("ØªØ§Ø±ÛŒØ® Ù†Ù…Ø§ÛŒØ´")[selected_cols_report].mean().reset_index()
            else:
                df_trend["ØªØ§Ø±ÛŒØ® Ù†Ù…Ø§ÛŒØ´"] = df_trend["ØªØ§Ø±ÛŒØ®"].map(lambda x: JalaliDate(x).strftime('%Y/%m'))
                df_trend = df_trend.groupby("ØªØ§Ø±ÛŒØ® Ù†Ù…Ø§ÛŒØ´")[selected_cols_report].mean().reset_index()
            
            if not df_trend.empty:
                fig_trend = px.line(
                    df_trend, 
                    x="ØªØ§Ø±ÛŒØ® Ù†Ù…Ø§ÛŒØ´", 
                    y=selected_cols_report, 
                    title=f"Ø±ÙˆÙ†Ø¯ Ù…ØµØ±Ù ({granularity})",
                    color_discrete_sequence=px.colors.qualitative.Set1
                )
                fig_trend.update_layout(
                    xaxis_title="ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ", 
                    yaxis_title="Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØµØ±Ù (MWh)", 
                    plot_bgcolor='white', 
                    paper_bgcolor='white'
                )
                
                st.plotly_chart(fig_trend, use_container_width=True)
                
                img_buffer = io.BytesIO()
                fig_trend.write_image(img_buffer, format='png', width=500, height=300, scale=2)
                img_buffer.seek(0)
                
                img = Image(img_buffer, width=500, height=300)
                elements.append(img)
                elements.append(Spacer(1, 12))
        
        title = "Ú¯Ø²Ø§Ø±Ø´ Ø³ÙØ§Ø±Ø´ÛŒ"
        if not use_persian:
            title = translations.get(title, title)
        generate_pdf(title, elements, buffer)
        
        # ğŸ‘ˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø§ getvalue() Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†
        pdf_data = buffer.getvalue()
        st.download_button("â¬‡ï¸ Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF", pdf_data, "Ú¯Ø²Ø§Ø±Ø´_Ø³ÙØ§Ø±Ø´ÛŒ.pdf", "application/pdf")
        
        if uploaded_font:
            os.remove("temp_font_tab16.ttf")
    
    if st.checkbox("ğŸ“± Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ ÙˆØ§ØªØ³Ø§Ù¾"):
        phone_number = st.text_input("ğŸ“ Ø´Ù…Ø§Ø±Ù‡ ÙˆØ§ØªØ³Ø§Ù¾ (Ø¨Ø§ +ØŒ Ù…Ø«Ù„ +989123456789):")
        message = st.text_area("ğŸ’¬ Ù…ØªÙ† Ù¾ÛŒØ§Ù… (PDF Ø±Ùˆ Ø¯Ø³ØªÛŒ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†):")
        
        if st.button("Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ ÙˆØ§ØªØ³Ø§Ù¾"):
            if not phone_number or not message:
                st.error("âš ï¸ Ø´Ù…Ø§Ø±Ù‡ Ùˆ Ù…ØªÙ† Ø±Ùˆ ÙˆØ§Ø±Ø¯ Ú©Ù†!")
                st.stop()
            
            import pywhatkit as pwk
            pwk.sendwhatmsg_instantly(phone_number, message)
            st.success("âœ… Ù¾ÛŒØ§Ù… Ø¨Ù‡ ÙˆØ§ØªØ³Ø§Ù¾ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯! (PDF Ø±Ùˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ùˆ Ø¯Ø³ØªÛŒ Ø¶Ù…ÛŒÙ…Ù‡ Ú©Ù†.)")
            st.download_button("ğŸ“ Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF Ø¨Ø±Ø§ÛŒ ÙˆØ§ØªØ³Ø§Ù¾", pdf_data, "Ú¯Ø²Ø§Ø±Ø´.pdf", "application/pdf")

# ----------- Tab17: Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ (Ø¯Ø§Ø±Ù‡ØŒ ØªØºÛŒÛŒØ± ÙÙˆÙ†Øª) -----------
with tab17:
    st.subheader("ğŸ² Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§")
    
    selected_scen = st.multiselect("ğŸ”® Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ (ØªØ¬Ù‡ÛŒØ²Ø§Øª):", columns, default=columns[:3])
    
    if selected_scen:
        base_means = filtered_df[selected_scen].mean()
        
        change_factor = st.slider("ğŸ“ˆ ÙØ§Ú©ØªÙˆØ± ØªØºÛŒÛŒØ± (Â±%):", 0, 50, 20)
        n_simulations = st.slider("ğŸ”„ ØªØ¹Ø¯Ø§Ø¯ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ:", 100, 5000, 1000)
        
        sim_df = monte_carlo_simulation(base_means.values, selected_scen, n_simulations, change_factor)
        
        for col in selected_scen:
            fig_hist = px.histogram(sim_df, x=col, title=f"ØªÙˆØ²ÛŒØ¹ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ {col} (Â±{change_factor}%)",
                                    color_discrete_sequence=['blue'])
            st.plotly_chart(fig_hist, use_container_width=True)
        
        summary = sim_df.describe().round(2)
        st.dataframe(summary)
        
        st.info(f"ğŸ’¡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ú©Ù„: {sim_df.mean().mean():.2f} MWh (ØªØºÛŒÛŒØ± Â±{change_factor}%)")
        
        st.markdown("### ğŸ“ ØªÙˆÙ„ÛŒØ¯ PDF Ú¯Ø²Ø§Ø±Ø´ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ")
        
        uploaded_font_sim = st.file_uploader("ğŸ–‹ Ø¢Ù¾Ù„ÙˆØ¯ ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ (TTF, Ù…Ø«Ù„ BNazanin.ttf)", type=["ttf"], key="sim_font")
        font_path_sim = None
        if uploaded_font_sim:
            with open("temp_sim_font.ttf", "wb") as f:
                f.write(uploaded_font_sim.getvalue())
            font_path_sim = "temp_sim_font.ttf"
        else:
            font_path_sim = r"D:\BNazanin.ttf"
            if not os.path.exists(font_path_sim):
                st.warning("âš ï¸ ÙÙˆÙ†Øª B Nazanin Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
        
        if st.button("ØªÙˆÙ„ÛŒØ¯ PDF", key="sim_pdf"):
            pdf_buffer = io.BytesIO()
            elements = []
            
            use_persian = available_fonts and font_name != "Helvetica"
            if font_path_sim and os.path.exists(font_path_sim):
                try:
                    pdfmetrics.registerFont(TTFont("BNazanin", font_path_sim))
                    title_style = ParagraphStyle(
                        name='TitleRTL',
                        parent=getSampleStyleSheet()['Title'],
                        fontName="BNazanin",
                        fontSize=18,
                        alignment=1
                    )
                    normal_style = ParagraphStyle(
                        name='RTLStyle',
                        parent=getSampleStyleSheet()['Normal'],
                        fontName="BNazanin",
                        fontSize=12,
                        leading=14,
                        alignment=1,
                        spaceAfter=12
                    )
                except Exception as e:
                    st.error(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± ÙÙˆÙ†Øª: {e}")
                    title_style = getSampleStyleSheet()['Title']
                    normal_style = getSampleStyleSheet()['Normal']
            else:
                title_style = getSampleStyleSheet()['Title']
                normal_style = getSampleStyleSheet()['Normal']
            
            title_text = f"Ú¯Ø²Ø§Ø±Ø´ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ (Â±{change_factor}%) - {n_simulations} ØªÚ©Ø±Ø§Ø±"
            elements.append(Paragraph(title_text, title_style))
            elements.append(Spacer(1, 12))
            
            elements.append(Paragraph("Ø¬Ø¯ÙˆÙ„ Ø¢Ù…Ø§Ø± ØªÙˆØµÛŒÙÛŒ", normal_style))
            summary_list = summary.reset_index().values.tolist()
            
            # ØªØ±Ø¬Ù…Ù‡ Ù‡Ø¯Ø±Ù‡Ø§ Ø§Ú¯Ø± Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
            translations_local = {
                # Add summary columns translations if needed
            }
            if not use_persian and summary_list and isinstance(summary_list[0], list):
                # Apply translations to headers
                pass  # Implement as needed
            
            # Reshape Ù…ØªÙ†â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ RTL Ø§Ú¯Ø± ÙØ§Ø±Ø³ÛŒ (ÙÙ‚Ø· Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§)
            if use_persian:
                try:
                    import arabic_reshaper
                    from bidi.algorithm import get_display
                    for row in summary_list:
                        for i, cell in enumerate(row):
                            if isinstance(cell, str):
                                row[i] = get_display(arabic_reshaper.reshape(cell))
                except ImportError:
                    st.warning("Ø¨Ø±Ø§ÛŒ RTL Ø¯Ø± Ø¬Ø¯ÙˆÙ„ØŒ arabic-reshaper Ùˆ python-bidi Ø±Ùˆ Ù†ØµØ¨ Ú©Ù†.")
            
            table = Table(summary_list)
            table.setStyle(TableStyle([
                ('BACKGROUND', (0,0), (-1,0), colors.lightblue),
                ('TEXTCOLOR', (0,0), (-1,-1), colors.black),
                ('GRID', (0,0), (-1,-1), 1, colors.darkblue),
                ('ALIGN', (0,0), (-1,-1), 'CENTER')
            ]))
            elements.append(table)
            elements.append(Spacer(1, 12))
            
            for col in selected_scen:
                fig_hist_pdf = px.histogram(sim_df, x=col, title=f"ØªÙˆØ²ÛŒØ¹ {col}",
                                            color_discrete_sequence=['blue'])
                fig_hist_pdf.update_layout(plot_bgcolor='white', paper_bgcolor='white')
                
                img_buffer = io.BytesIO()
                fig_hist_pdf.write_image(img_buffer, format='png', width=500, height=300, scale=2)
                img_buffer.seek(0)
                img = Image(img_buffer, width=500, height=300)
                elements.append(Paragraph(f"Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù… {col}", normal_style))
                elements.append(img)
                elements.append(Spacer(1, 12))
            
            title = "Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§"
            if not use_persian:
                title = translations.get(title, title)
            generate_pdf(title, elements, pdf_buffer)
            
            # ğŸ‘ˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø§ getvalue() Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†
            pdf_data = pdf_buffer.getvalue()
            st.download_button("â¬‡ï¸ Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ", pdf_data, "Ø´Ø¨ÛŒÙ‡_Ø³Ø§Ø²ÛŒ_Ù…ÙˆÙ†Øª_Ú©Ø§Ø±Ù„Ùˆ.pdf", "application/pdf")
            
            if uploaded_font_sim:
                os.remove("temp_sim_font.ttf")

# ----------- Tab18: Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ -----------
with tab18:
    st.subheader("âš™ï¸ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ (LP/NLP)")
    
    opt_type = st.selectbox("Ù†ÙˆØ¹ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ:", ["Ø®Ø·ÛŒ (LP)", "ØºÛŒØ±Ø®Ø·ÛŒ (NLP)"])
    
    if opt_type == "Ø®Ø·ÛŒ (LP)":
        st.markdown("### Ù…Ø«Ø§Ù„ LP: Ø­Ø¯Ø§Ù‚Ù„ Ù‡Ø²ÛŒÙ†Ù‡ Ù…ØµØ±Ù ØªØ¬Ù‡ÛŒØ²Ø§Øª")
        
        selected_equip = st.multiselect("ØªØ¬Ù‡ÛŒØ²Ø§Øª:", columns)
        if selected_equip:
            costs = {col: st.number_input(f"Ù‡Ø²ÛŒÙ†Ù‡ {col} (ØªÙˆÙ…Ø§Ù†/MWh):", value=1000.0, key=f"cost_{col}") for col in selected_equip}
            
            min_total = st.number_input("Ø­Ø¯Ø§Ù‚Ù„ Ù…Ø¬Ù…ÙˆØ¹ Ù…ØµØ±Ù (MWh):", value=100.0)
            max_per_equip = st.number_input("Ø­Ø¯Ø§Ú©Ø«Ø± Ù‡Ø± ØªØ¬Ù‡ÛŒØ² (MWh):", value=50.0)
            
            if st.button("Ø­Ù„ LP"):
                prob = LpProblem("Ø¨Ù‡ÛŒÙ†Ù‡_Ù…ØµØ±Ù_Ø¨Ø±Ù‚", LpMinimize)
                
                vars_dict = {col: LpVariable(col, lowBound=0, upBound=max_per_equip) for col in selected_equip}
                
                prob += sum(costs[col] * vars_dict[col] for col in selected_equip)
                
                prob += sum(vars_dict[col] for col in selected_equip) >= min_total
                
                prob.solve()
                
                if LpStatus[prob.status] == "Optimal":
                    results = {col: value(vars_dict[col]) for col in selected_equip}
                    total_cost = value(prob.objective)
                    
                    res_df = pd.DataFrame(list(results.items()), columns=["ØªØ¬Ù‡ÛŒØ²", "Ù…ØµØ±Ù Ø¨Ù‡ÛŒÙ†Ù‡ (MWh)"])
                    res_df["Ù‡Ø²ÛŒÙ†Ù‡ (ØªÙˆÙ…Ø§Ù†)"] = [costs[col] * results[col] for col in selected_equip]
                    st.dataframe(res_df)
                    
                    st.metric("Ù‡Ø²ÛŒÙ†Ù‡ Ú©Ù„ Ø¨Ù‡ÛŒÙ†Ù‡", f"{total_cost:.0f} ØªÙˆÙ…Ø§Ù†")
                    
                    fig = px.bar(res_df, x="ØªØ¬Ù‡ÛŒØ²", y="Ù…ØµØ±Ù Ø¨Ù‡ÛŒÙ†Ù‡ (MWh)", title="ØªØ®ØµÛŒØµ Ø¨Ù‡ÛŒÙ†Ù‡")
                    st.plotly_chart(fig, use_container_width=True)

                    # Ø®Ø±ÙˆØ¬ÛŒ PDF Ø¨Ø±Ø§ÛŒ Tab18 LP
                    if st.button("â¬‡ï¸ Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF LP Tab18"):
                        buffer = io.BytesIO()
                        elements = []
                        
                        data = [res_df.columns.tolist()] + res_df.values.tolist()
                        
                        # ØªØ±Ø¬Ù…Ù‡ Ù‡Ø¯Ø±Ù‡Ø§ Ø§Ú¯Ø± Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
                        translations_local = {
                            "ØªØ¬Ù‡ÛŒØ²": "Equipment",
                            "Ù…ØµØ±Ù Ø¨Ù‡ÛŒÙ†Ù‡ (MWh)": "Optimized Consumption (MWh)",
                            "Ù‡Ø²ÛŒÙ†Ù‡ (ØªÙˆÙ…Ø§Ù†)": "Cost (Toman)"
                        }
                        use_persian = available_fonts and font_name != "Helvetica"
                        if not use_persian and data and isinstance(data[0], list) and len(data[0]) >= 3:
                            data[0][0] = translations_local.get(data[0][0], data[0][0])
                            data[0][1] = translations_local.get(data[0][1], data[0][1])
                            data[0][2] = translations_local.get(data[0][2], data[0][2])
                        
                        # Reshape Ù…ØªÙ†â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ RTL Ø§Ú¯Ø± ÙØ§Ø±Ø³ÛŒ (ÙÙ‚Ø· Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§)
                        if use_persian:
                            try:
                                import arabic_reshaper
                                from bidi.algorithm import get_display
                                for row in data:
                                    for i, cell in enumerate(row):
                                        if isinstance(cell, str):
                                            row[i] = get_display(arabic_reshaper.reshape(cell))
                            except ImportError:
                                st.warning("Ø¨Ø±Ø§ÛŒ RTL Ø¯Ø± Ø¬Ø¯ÙˆÙ„ØŒ arabic-reshaper Ùˆ python-bidi Ø±Ùˆ Ù†ØµØ¨ Ú©Ù†.")
                        
                        table = Table(data)
                        table.setStyle(TableStyle([
                            ('BACKGROUND', (0,0), (-1,0), colors.lightgrey),  # Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ø¹Ù†ÙˆØ§Ù†
                            ('TEXTCOLOR', (0,0), (-1,0), colors.black),       # Ù…ØªÙ† Ø¹Ù†ÙˆØ§Ù†
                            ('GRID', (0,0), (-1,-1), 0.5, colors.lightgrey),  # ğŸ‘ˆ grid Ú©Ù…â€ŒØ±Ù†Ú¯ (Ù†Ù‡ Ù…Ø´Ú©ÛŒ)
                            ('ALIGN', (0,0), (-1,-1), 'CENTER')
                        ]))
                        elements.append(table)
                        
                        # ØªÙˆÙ„ÛŒØ¯ ØªØµÙˆÛŒØ± Ø¨Ø§ Ú©ÛŒÙÛŒØª Ø¨Ù‡ØªØ± (Ù†ÛŒØ§Ø² Ø¨Ù‡ kaleido: pip install kaleido)
                        img_buf = io.BytesIO()
                        fig.write_image(img_buf, format='png', width=800, height=400, scale=2)
                        img_buf.seek(0)
                        elements.append(Image(img_buf, width=500, height=300))
                        
                        title = "Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ LP"
                        if not use_persian:
                            title = translations.get(title, title)
                        generate_pdf(title, elements, buffer)
                        
                        # ğŸ‘ˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø§ getvalue() Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†
                        pdf_data = buffer.getvalue()
                        st.download_button(
                            label="Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF",
                            data=pdf_data,
                            file_name="tab18_lp.pdf",
                            mime="application/pdf"
                        )
                        
                        # Ú†Ú© ÙÙˆÙ†Øª
                        if not available_fonts:
                            st.warning("âš ï¸ ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. PDF Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯.")
                else:
                    st.error("Ø±Ø§Ù‡â€ŒØ­Ù„ Ø¨Ù‡ÛŒÙ†Ù‡ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯!")
    
    else:
        st.markdown("### Ù…Ø«Ø§Ù„ NLP: Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ ØºÛŒØ±Ø®Ø·ÛŒ (scipy)")
        from scipy.optimize import minimize
        
        def objective(x):
            return x[0]**2 + x[1]**2
        
        constraints = ({'type': 'eq', 'fun': lambda x: x[0] + x[1] - 10})
        bounds = [(0, None), (0, None)]
        
        res = minimize(objective, [1, 1], method='SLSQP', bounds=bounds, constraints=constraints)
        
        st.write(f"Ù†ØªØ§ÛŒØ¬ NLP: x={res.x[0]:.2f}, y={res.x[1]:.2f}, Ù…Ù‚Ø¯Ø§Ø± Ù‡Ø¯Ù={res.fun:.2f}")

        # Ø®Ø±ÙˆØ¬ÛŒ PDF Ø¨Ø±Ø§ÛŒ Tab18 NLP
        if st.button("â¬‡ï¸ Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF NLP Tab18"):
            buffer = io.BytesIO()
            elements = []
            
            # ØªØ±Ø¬Ù…Ù‡ Ù‡Ø¯Ø±Ù‡Ø§ Ø§Ú¯Ø± Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
            translations_local = {
                # For text
            }
            use_persian = available_fonts and font_name != "Helvetica"
            text = f"Ù†ØªØ§ÛŒØ¬ NLP: x={res.x[0]:.2f}, y={res.x[1]:.2f}, Ù…Ù‚Ø¯Ø§Ø± Ù‡Ø¯Ù={res.fun:.2f}"
            if not use_persian:
                text = "NLP Results: x={:.2f}, y={:.2f}, objective={:.2f}".format(res.x[0], res.x[1], res.fun)
            
            # Reshape Ù…ØªÙ†â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ RTL Ø§Ú¯Ø± ÙØ§Ø±Ø³ÛŒ (ÙÙ‚Ø· Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§)
            if use_persian:
                try:
                    import arabic_reshaper
                    from bidi.algorithm import get_display
                    text = get_display(arabic_reshaper.reshape(text))
                except ImportError:
                    st.warning("Ø¨Ø±Ø§ÛŒ RTL Ø¯Ø± Ø¬Ø¯ÙˆÙ„ØŒ arabic-reshaper Ùˆ python-bidi Ø±Ùˆ Ù†ØµØ¨ Ú©Ù†.")
            
            elements.append(Paragraph(text, ParagraphStyle('Normal', alignment=1 if use_persian else 0)))
            
            title = "Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ NLP"
            if not use_persian:
                title = translations.get(title, title)
            generate_pdf(title, elements, buffer)
            
            # ğŸ‘ˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø§ getvalue() Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†
            pdf_data = buffer.getvalue()
            st.download_button(
                label="Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF",
                data=pdf_data,
                file_name="tab18_nlp.pdf",
                mime="application/pdf"
            )
            
            # Ú†Ú© ÙÙˆÙ†Øª
            if not available_fonts:
                st.warning("âš ï¸ ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. PDF Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯.")